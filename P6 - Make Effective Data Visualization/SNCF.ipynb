{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNCF - TGV regularity visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import, cleaning and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "## Read CSV\n",
    "df = pd.read_csv(\"data/regularite-mensuelle-tgv.csv\", encoding=\"utf8\", sep=';')\n",
    "\n",
    "## Drop NaN values\n",
    "df = df.dropna(subset=df.columns.drop('Commentaires'))\n",
    "\n",
    "## Create additional column with city set \n",
    "df[\"cities\"] = list(map(lambda a, b: frozenset([a, b]), df[\"Départ\"], df[\"Arrivée\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify causes for train disturbances in the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disturbance = {\"obs_person\": ['personne','voiture','tracteur','vol ','incendie','colis','alerte','pompier','police','bagages'],\n",
    "               \"obs_animal\": ['animal','animaux','chevreuil','oiseau','sanglier','vaches'],\n",
    "               \"obs_technical\": ['problème','défaillance','défaut','disjonction','dérangements','panne','rupture','cassé',\n",
    "                                'caténaire','incident','aiguillage'],\n",
    "               \"obs_malicious\": ['malveillance'],\n",
    "               \"obs_construction\": ['travaux'],\n",
    "               \"obs_strike\": ['grève','social','manifestants'],\n",
    "               \"obs_weather\": ['intempérie','précipitation','inondation','chaleur','arbre','branchage','neige','foudre','orage']}\n",
    "\n",
    "def find_word(words, sentence):\n",
    "    # this function returns 1 if one of the word in the list is found in the given sentence.\n",
    "    # it returns 0 otherwise\n",
    "    count = 0\n",
    "    if str(sentence) == 'nan':\n",
    "        return count\n",
    "    else:\n",
    "        for word in words:\n",
    "            if sentence.find(word) == -1:\n",
    "                pass\n",
    "            else:\n",
    "                count += 1\n",
    "        return min(count,1)  \n",
    "\n",
    "# check for each disturbance family if the observation contains related words\n",
    "for key,value in disturbance.items():\n",
    "    df[key] = list(map(lambda a: find_word(value,a),df[\"Commentaires\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train regularity statistics per railway section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Groupby Date and Cities\n",
    "g1 = df.groupby([\"Date\", \"cities\"]).sum()\n",
    "g1 = g1.reset_index()\n",
    "g1[\"Régularité\"] = 1 - 1.0*(g1[\"Nombre de trains annulés\"] + g1[\"Nombre de trains en retard à l'arrivée\"])\\\n",
    "    /g1[\"Nombre de trains programmés\"]\n",
    "g1[\"year\"] = list(map(lambda x: int(x[0:4]), g1.Date))\n",
    "g1[\"month\"] = list(map(lambda x: int(x[5:]), g1.Date))\n",
    "g1[\"datetime\"]=pd.to_datetime(g1.Date)\n",
    "\n",
    "\n",
    "# train_lines dictionnary binds train lines names with the rail sections that are concerned. This dictionnary is then used to\n",
    "# aggregate the total number of trains running on a specific rail section.\n",
    "\n",
    "train_lines = defaultdict()\n",
    "train_lines[frozenset(['NICE VILLE', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2', 'S1_1_1_1_2_1', \n",
    "                                                        'S1_1_1_1_2_1_2', 'S1_1_1_1_2_1_2_1', 'S1_1_1_1_2_1_2_1_1', \n",
    "                                                        'S1_1_1_1_2_1_2_1_1_1']\n",
    "train_lines[frozenset(['PARIS LYON', 'TOULON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2', 'S1_1_1_1_2_1', \n",
    "                                                    'S1_1_1_1_2_1_2', 'S1_1_1_1_2_1_2_1', 'S1_1_1_1_2_1_2_1_1']\n",
    "train_lines[frozenset(['MARSEILLE ST CHARLES', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2', 'S1_1_1_1_2_1', \n",
    "                                                                  'S1_1_1_1_2_1_2', 'S1_1_1_1_2_1_2_1']\n",
    "train_lines[frozenset(['AIX EN PROVENCE TGV', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2', 'S1_1_1_1_2_1', \n",
    "                                                                 'S1_1_1_1_2_1_2']\n",
    "train_lines[frozenset(['AVIGNON TGV', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2', 'S1_1_1_1_2_1']\n",
    "train_lines[frozenset(['PARIS LYON', 'VALENCE ALIXAN TGV'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'TOURS'])] = ['A1','A1_2']\n",
    "train_lines[frozenset(['CHAMBERY CHALLES LES EAUX', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_3']\n",
    "train_lines[frozenset(['BELLEGARDE (AIN)', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_3','S1_1_1_1_3_3']\n",
    "train_lines[frozenset(['ANNECY', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_3','S1_1_1_1_3_2']\n",
    "train_lines[frozenset(['METZ', 'PARIS EST'])] = ['E1','E1_1']\n",
    "train_lines[frozenset(['BORDEAUX ST JEAN', 'PARIS MONTPARNASSE'])] = ['A1','A1_2','A1_2_1','A1_2_1_2','A1_2_1_2_1']\n",
    "train_lines[frozenset(['LE CREUSOT MONTCEAU MONTCHANIN', 'PARIS LYON'])] = ['S1','S1_1']\n",
    "train_lines[frozenset(['DUNKERQUE', 'PARIS NORD'])] = ['N1','N1_3','N1_3_1']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'TOULOUSE MATABIAU'])] = ['A1','A1_2','A1_2_1','A1_2_1_2','A1_2_1_2_1',\n",
    "                                                                       'A1_2_1_2_1_1']\n",
    "train_lines[frozenset(['LILLE', 'PARIS NORD'])] = ['N1','N1_2']\n",
    "train_lines[frozenset(['LILLE', 'MARSEILLE ST CHARLES'])] = ['N1','N1_2','S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2', \n",
    "                                                             'S1_1_1_1_2_1','S1_1_1_1_2_1_2','S1_1_1_1_2_1_2_1']\n",
    "train_lines[frozenset(['LYON PART DIEU', 'MARSEILLE ST CHARLES'])] = ['S1_1_1_1_2','S1_1_1_1_2_1','S1_1_1_1_2_1_2',\n",
    "                                                                      'S1_1_1_1_2_1_2_1']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'QUIMPER'])] = ['A1','A1_1','A1_1_1','A1_1_1_3','A1_1_1_3_1']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'RENNES'])] = ['A1','A1_1','A1_1_1']\n",
    "train_lines[frozenset(['ANGERS SAINT LAUD', 'PARIS MONTPARNASSE'])] = ['A1','A1_1','A1_1_2']\n",
    "train_lines[frozenset(['NANTES', 'STRASBOURG'])] = ['A1','A1_1','A1_1_2','A1_1_2_1','E1','E1_1','E1_1_1']\n",
    "train_lines[frozenset(['MULHOUSE VILLE', 'PARIS LYON'])] = ['S1','S1_2','S1_2_1','S1_2_1_1']\n",
    "train_lines[frozenset(['NANTES', 'PARIS MONTPARNASSE'])] = ['A1','A1_1','A1_1_2','A1_1_2_1']\n",
    "train_lines[frozenset(['LYON PART DIEU', 'MONTPELLIER'])] = ['S1_1_1_1_2','S1_1_1_1_2_1','S1_1_1_1_2_1_1','S1_1_1_1_2_1_1_1']\n",
    "train_lines[frozenset(['LYON PART DIEU', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'ST MALO'])] = ['A1','A1_1','A1_1_1','A1_1_1_1']\n",
    "train_lines[frozenset(['LYON PART DIEU', 'RENNES'])] = ['A1','A1_1','A1_1_1','S1','S1_1','S1_1_1','S1_1_1_1']\n",
    "train_lines[frozenset(['MONTPELLIER', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2','S1_1_1_1_2_1',\n",
    "                                                         'S1_1_1_1_2_1_1','S1_1_1_1_2_1_1_1']\n",
    "train_lines[frozenset(['ANGOULEME', 'PARIS MONTPARNASSE'])] = ['A1','A1_2','A1_2_1','A1_2_1_2']\n",
    "train_lines[frozenset(['GRENOBLE', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_3','S1_1_1_1_3_1']\n",
    "train_lines[frozenset(['PARIS EST', 'STRASBOURG'])] = ['E1','E1_1','E1_1_1']\n",
    "train_lines[frozenset(['PARIS LYON', 'SAINT ETIENNE CHATEAUCREUX'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_1']\n",
    "train_lines[frozenset(['DIJON VILLE', 'PARIS LYON'])] = ['S1','S1_2']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'ST PIERRE DES CORPS'])] = ['A1','A1_2']\n",
    "train_lines[frozenset(['NANCY', 'PARIS EST'])] = ['E1','E1_1']\n",
    "train_lines[frozenset(['NIMES', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2','S1_1_1_1_2_1','S1_1_1_1_2_1_1']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'POITIERS'])] = ['A1','A1_2','A1_2_1']\n",
    "train_lines[frozenset(['LA ROCHELLE VILLE', 'PARIS MONTPARNASSE'])] = ['A1','A1_2','A1_2_1','A1_2_1_1']\n",
    "train_lines[frozenset(['LILLE', 'LYON PART DIEU'])] = ['N1','N1_2','S1','S1_1','S1_1_1','S1_1_1_1']\n",
    "train_lines[frozenset(['PARIS MONTPARNASSE', 'VANNES'])] = ['A1','A1_1','A1_1_1','A1_1_1_3']\n",
    "train_lines[frozenset(['ARRAS', 'PARIS NORD'])] = ['N1','N1_3']\n",
    "train_lines[frozenset(['PARIS LYON', 'PERPIGNAN'])] = ['S1','S1_1','S1_1_1','S1_1_1_1','S1_1_1_1_2','S1_1_1_1_2_1',\n",
    "                                                         'S1_1_1_1_2_1_1','S1_1_1_1_2_1_1_1','S1_1_1_1_2_1_1_1_1']\n",
    "train_lines[frozenset(['LE MANS', 'PARIS MONTPARNASSE'])] = ['A1','A1_1']\n",
    "train_lines[frozenset(['MACON LOCHE', 'PARIS LYON'])] = ['S1','S1_1','S1_1_1']\n",
    "train_lines[frozenset(['DOUAI', 'PARIS NORD'])] = ['N1','N1_1']\n",
    "train_lines[frozenset(['BESANCON FRANCHE COMTE TGV', 'PARIS LYON'])] = ['S1','S1_2','S1_2_1']\n",
    "train_lines[frozenset(['BREST', 'PARIS MONTPARNASSE'])] = ['A1','A1_1','A1_1_1','A1_1_1_2']\n",
    "train_lines[frozenset(['PARIS EST', 'REIMS'])] = ['E1']\n",
    "train_lines[frozenset(['LAVAL', 'PARIS MONTPARNASSE'])] = ['A1','A1_1']\n",
    "\n",
    "# assign the different rail sections list to each dataframe entry\n",
    "g1[\"line_section\"] = list(map(lambda x: train_lines[x], g1.cities))\n",
    "\n",
    "# duplicate rows for each rail section. set line_section value to line section name\n",
    "g2 = pd.DataFrame()\n",
    "for ii in range(len(g1)):\n",
    "    for jj in range(len(g1['line_section'][ii])):\n",
    "        row = g1.iloc[ii,:].copy()\n",
    "        row.loc['line_section'] = g1.loc[ii,'line_section'][jj]\n",
    "        g2 = g2.append(row,ignore_index=True)\n",
    "\n",
    "# Groupby line_section\n",
    "g3 = g2.groupby([\"Date\", \"line_section\"]).sum()\n",
    "g3 = g3.reset_index()\n",
    "g3[\"regularity\"] = 1 - 1.0*(g3[\"Nombre de trains annulés\"] + g3[\"Nombre de trains en retard à l'arrivée\"])\\\n",
    "    /g3[\"Nombre de trains programmés\"]\n",
    "g3[\"year\"] = list(map(lambda x: int(x[0:4]), g3.Date))\n",
    "g3[\"month\"] = list(map(lambda x: int(x[5:]), g3.Date))\n",
    "g3[\"datetime\"]=pd.to_datetime(g3.Date)\n",
    "g3.head()\n",
    "\n",
    "# export to tsv file\n",
    "g3.to_csv('data/regularity.tsv', sep='\\t', columns=['Date','year','month','line_section','regularity'], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>line_section</th>\n",
       "      <th>Nombre de trains annulés</th>\n",
       "      <th>Nombre de trains ayant circulé</th>\n",
       "      <th>Nombre de trains en retard à l'arrivée</th>\n",
       "      <th>Nombre de trains programmés</th>\n",
       "      <th>Régularité</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09</td>\n",
       "      <td>A1</td>\n",
       "      <td>0</td>\n",
       "      <td>10752</td>\n",
       "      <td>806</td>\n",
       "      <td>10752</td>\n",
       "      <td>0.925037</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09</td>\n",
       "      <td>A1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>6023</td>\n",
       "      <td>398</td>\n",
       "      <td>6023</td>\n",
       "      <td>0.933920</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09</td>\n",
       "      <td>A1_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>2391</td>\n",
       "      <td>139</td>\n",
       "      <td>2391</td>\n",
       "      <td>0.941865</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09</td>\n",
       "      <td>A1_1_1_1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09</td>\n",
       "      <td>A1_1_1_2</td>\n",
       "      <td>0</td>\n",
       "      <td>372</td>\n",
       "      <td>16</td>\n",
       "      <td>372</td>\n",
       "      <td>0.956989</td>\n",
       "      <td>9</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011-09-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date line_section  Nombre de trains annulés  \\\n",
       "0  2011-09           A1                         0   \n",
       "1  2011-09         A1_1                         0   \n",
       "2  2011-09       A1_1_1                         0   \n",
       "3  2011-09     A1_1_1_1                         0   \n",
       "4  2011-09     A1_1_1_2                         0   \n",
       "\n",
       "   Nombre de trains ayant circulé  Nombre de trains en retard à l'arrivée  \\\n",
       "0                           10752                                     806   \n",
       "1                            6023                                     398   \n",
       "2                            2391                                     139   \n",
       "3                             114                                       1   \n",
       "4                             372                                      16   \n",
       "\n",
       "   Nombre de trains programmés  Régularité  month  year   datetime  \n",
       "0                        10752    0.925037      9  2011 2011-09-01  \n",
       "1                         6023    0.933920      9  2011 2011-09-01  \n",
       "2                         2391    0.941865      9  2011 2011-09-01  \n",
       "3                          114    0.991228      9  2011 2011-09-01  \n",
       "4                          372    0.956989      9  2011 2011-09-01  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of comments per train line per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# Read CSV\n",
    "df2 = pd.read_csv(\"data/regularite-mensuelle-tgv.csv\", encoding=\"utf8\", sep=';')\n",
    "\n",
    "# Drop NaN values\n",
    "df2 = df.dropna()\n",
    "\n",
    "# Drop non-used columns\n",
    "df2 = df2.drop([\"Axe\", \"Nombre de trains programmés\",\"Nombre de trains ayant circulé\", \n",
    "               \"Nombre de trains annulés\",\"Nombre de trains en retard à l'arrivée\"],1)\n",
    "'''\n",
    "# export to tsv file\n",
    "df.to_csv('data/comments.tsv', sep='\\t', columns=['Date','Départ','Arrivée','Commentaires','regularity','obs_person','obs_animal',\n",
    "                                                  'obs_weather','obs_malicious','obs_construction','obs_strike','obs_technical'], \n",
    "          index=False, encoding=\"utf8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5895 entries, 0 to 5899\n",
      "Data columns (total 18 columns):\n",
      "Date                                      5895 non-null object\n",
      "Axe                                       5895 non-null object\n",
      "Départ                                    5895 non-null object\n",
      "Arrivée                                   5895 non-null object\n",
      "Nombre de trains programmés               5895 non-null float64\n",
      "Nombre de trains ayant circulé            5895 non-null float64\n",
      "Nombre de trains annulés                  5895 non-null float64\n",
      "Nombre de trains en retard à l'arrivée    5895 non-null float64\n",
      "Régularité                                5895 non-null float64\n",
      "Commentaires                              1105 non-null object\n",
      "cities                                    5895 non-null object\n",
      "obs_person                                5895 non-null int64\n",
      "obs_animal                                5895 non-null int64\n",
      "obs_weather                               5895 non-null int64\n",
      "obs_malicious                             5895 non-null int64\n",
      "obs_construction                          5895 non-null int64\n",
      "obs_strike                                5895 non-null int64\n",
      "obs_technical                             5895 non-null int64\n",
      "dtypes: float64(5), int64(7), object(6)\n",
      "memory usage: 875.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
