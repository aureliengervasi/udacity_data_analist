{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#P3 Wrangle OSM Data with MongoDB - Paris Metroline\n",
    "\n",
    "**Map area : Paris metroline, France**\n",
    "\n",
    "Source : https://mapzen.com/data/metro-extracts/\n",
    "\n",
    "The goal of this work...\n",
    "Learn how to process data before storing it in \n",
    "https://classroom.udacity.com/nanodegrees/nd002/parts/0021345404/modules/316820862075463/lessons/3168208620239847/concepts/77095517320923\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##I need a smaller file to play with...\n",
    "\n",
    "In order to run my first scripts, test them, and debug them, I need to use a smaller file than the entire Paris OSM data (4.4GB). The following code simply produces a file based on the original OSM data but limited to the first 100 000 lines.\n",
    "\n",
    "The final version of the work is done on the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "lines = 10000 # maximum number of lines to be copied in the smaller file\n",
    "file_in = 'data\\\\paris_france.osm'\n",
    "file_out = '{0}_extract.{1}'.format(file_in.split('.')[0], file_in.split('.')[1])\n",
    "i = 0\n",
    "with codecs.open(file_out, 'w') as fo:\n",
    "    with codecs.open(file_in, 'r') as fi:\n",
    "        for line in fi:\n",
    "            if i < lines:\n",
    "                i += 1\n",
    "                fo.write(line)\n",
    "            elif i == lines:\n",
    "                fo.write('</osm>')    # Adding osm end tag in the end of the file to close the osm tag from the file start\n",
    "                i += 1\n",
    "            else:\n",
    "                break\n",
    "filename = file_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Some first look at the data...\n",
    "\n",
    "###What are the main kind of element in the data?\n",
    "\n",
    "The following code finds out what type of element are there, but also how many, to get the\n",
    "feeling of how much of each type of data I can expect to find in the OSM map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bounds': 1,\n",
      " 'member': 485026,\n",
      " 'nd': 24986099,\n",
      " 'node': 18588534,\n",
      " 'osm': 1,\n",
      " 'relation': 35382,\n",
      " 'tag': 9670757,\n",
      " 'way': 3059389}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename):\n",
    "        if elem.tag in tags:\n",
    "            tags[elem.tag] += 1\n",
    "        else:\n",
    "            tags[elem.tag] = 1\n",
    "        elem.clear()\n",
    "    return tags\n",
    "\n",
    "tags = count_tags('data\\\\paris_france.osm')\n",
    "pprint.pprint(tags)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is consistant with the OSM standard schema. For the MongoDB database, we will not import the 'bounds' and 'osm' elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###What is the quality of the 'k' entries from the tag value ?\n",
    "The following code reuses some work from the problem sets, and checks the \"k\" value for each \"<tag>\" in order to see if they can be valid keys in MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'problemchars': 0, 'lower': 8545836, 'other': 255948, 'lower_colon': 868973}\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "\n",
    "for _, element in ET.iterparse('data\\\\paris_france.osm'):\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.get('k')\n",
    "            if re.match(lower, k):\n",
    "                keys['lower'] += 1\n",
    "            elif re.match(lower_colon, k):\n",
    "                keys['lower_colon'] += 1\n",
    "            elif re.match(problemchars, k):\n",
    "                keys['problemchars'] += 1   \n",
    "            else :\n",
    "                keys['other'] += 1   \n",
    "    element.clear()\n",
    "print keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is no problematical character for these entries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Which entries chould be transfered to the MongoDB database ?\n",
    "\n",
    "I already know that I will transfer some basic entries, like information about its creation, or the geoposition data.\n",
    "\n",
    "But I also want to have a better idea about the kind of tags that are the most frequent in my OSM data. By spotting the most frequent tag, I will be able to better focus my work on the data which is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 % of original file has been processed\n",
      "2.0 % of original file has been processed\n",
      "3.0 % of original file has been processed\n",
      "4.0 % of original file has been processed\n",
      "5.0 % of original file has been processed\n",
      "6.0 % of original file has been processed\n",
      "7.0 % of original file has been processed\n",
      "8.0 % of original file has been processed\n",
      "9.0 % of original file has been processed\n",
      "10.0 % of original file has been processed\n",
      "11.0 % of original file has been processed\n",
      "12.0 % of original file has been processed\n",
      "13.0 % of original file has been processed\n",
      "14.0 % of original file has been processed\n",
      "15.0 % of original file has been processed\n",
      "16.0 % of original file has been processed\n",
      "17.0 % of original file has been processed\n",
      "18.0 % of original file has been processed\n",
      "19.0 % of original file has been processed\n",
      "20.0 % of original file has been processed\n",
      "21.0 % of original file has been processed\n",
      "22.0 % of original file has been processed\n",
      "23.0 % of original file has been processed\n",
      "24.0 % of original file has been processed\n",
      "25.0 % of original file has been processed\n",
      "26.0 % of original file has been processed\n",
      "27.0 % of original file has been processed\n",
      "28.0 % of original file has been processed\n",
      "29.0 % of original file has been processed\n",
      "30.0 % of original file has been processed\n",
      "31.0 % of original file has been processed\n",
      "32.0 % of original file has been processed\n",
      "33.0 % of original file has been processed\n",
      "34.0 % of original file has been processed\n",
      "35.0 % of original file has been processed\n",
      "36.0 % of original file has been processed\n",
      "37.0 % of original file has been processed\n",
      "38.0 % of original file has been processed\n",
      "39.0 % of original file has been processed\n",
      "40.0 % of original file has been processed\n",
      "41.0 % of original file has been processed\n",
      "42.0 % of original file has been processed\n",
      "43.0 % of original file has been processed\n",
      "44.0 % of original file has been processed\n",
      "45.0 % of original file has been processed\n",
      "46.0 % of original file has been processed\n",
      "47.0 % of original file has been processed\n",
      "48.0 % of original file has been processed\n",
      "49.0 % of original file has been processed\n",
      "50.0 % of original file has been processed\n",
      "51.0 % of original file has been processed\n",
      "52.0 % of original file has been processed\n",
      "53.0 % of original file has been processed\n",
      "54.0 % of original file has been processed\n",
      "55.0 % of original file has been processed\n",
      "56.0 % of original file has been processed\n",
      "57.0 % of original file has been processed\n",
      "58.0 % of original file has been processed\n",
      "59.0 % of original file has been processed\n",
      "60.0 % of original file has been processed\n",
      "61.0 % of original file has been processed\n",
      "62.0 % of original file has been processed\n",
      "63.0 % of original file has been processed\n",
      "64.0 % of original file has been processed\n",
      "65.0 % of original file has been processed\n",
      "66.0 % of original file has been processed\n",
      "67.0 % of original file has been processed\n",
      "68.0 % of original file has been processed\n",
      "69.0 % of original file has been processed\n",
      "70.0 % of original file has been processed\n",
      "71.0 % of original file has been processed\n",
      "72.0 % of original file has been processed\n",
      "73.0 % of original file has been processed\n",
      "74.0 % of original file has been processed\n",
      "75.0 % of original file has been processed\n",
      "76.0 % of original file has been processed\n",
      "77.0 % of original file has been processed\n",
      "78.0 % of original file has been processed\n",
      "79.0 % of original file has been processed\n",
      "80.0 % of original file has been processed\n",
      "81.0 % of original file has been processed\n",
      "82.0 % of original file has been processed\n",
      "83.0 % of original file has been processed\n",
      "84.0 % of original file has been processed\n",
      "85.0 % of original file has been processed\n",
      "86.0 % of original file has been processed\n",
      "87.0 % of original file has been processed\n",
      "88.0 % of original file has been processed\n",
      "89.0 % of original file has been processed\n",
      "90.0 % of original file has been processed\n",
      "91.0 % of original file has been processed\n",
      "92.0 % of original file has been processed\n",
      "93.0 % of original file has been processed\n",
      "('source', 3278433)\n",
      "('building', 2593649)\n",
      "('wall', 547184)\n",
      "('highway', 423349)\n",
      "('addr:housenumber', 355761)\n",
      "('name', 277911)\n",
      "('addr:street', 169349)\n",
      "('natural', 151786)\n",
      "('amenity', 92903)\n",
      "('oneway', 80248)\n",
      "('ref:opendataparis:domanialit', 62708)\n",
      "('ref:opendataparis:geo_point_2d', 62708)\n",
      "('ref:opendataparis:adresse', 62708)\n",
      "('taxon:species', 62668)\n",
      "('building:levels', 55179)\n",
      "('genus', 53394)\n",
      "('addr:postcode', 49649)\n",
      "('addr:city', 47657)\n",
      "('ref', 44070)\n",
      "('circumference', 39147)\n",
      "('height', 37859)\n",
      "('type', 37239)\n",
      "('maxspeed', 33527)\n",
      "('operator', 33323)\n",
      "('access', 33077)\n",
      "('surface', 31852)\n",
      "('barrier', 31108)\n",
      "('addr:country', 29145)\n",
      "('service', 27958)\n",
      "('layer', 25762)\n",
      "('landuse', 25318)\n",
      "('shop', 25073)\n",
      "('railway', 22676)\n",
      "('leisure', 20973)\n",
      "('bicycle', 19864)\n",
      "('foot', 19245)\n",
      "('level', 18827)\n",
      "('lanes', 17098)\n",
      "('wheelchair', 16320)\n",
      "('gauge', 13614)\n",
      "('note', 13230)\n",
      "('crossing', 12800)\n",
      "('taxon:species:varietas', 11842)\n",
      "('lit', 11775)\n",
      "('sport', 10391)\n",
      "('tourism', 10371)\n",
      "('power', 9740)\n",
      "('voltage', 9314)\n",
      "('electrified', 8896)\n",
      "('bridge', 8650)\n",
      "('cycleway', 8613)\n",
      "('shelter', 8409)\n",
      "('frequency', 8353)\n",
      "('emergency', 7966)\n",
      "('man_made', 7305)\n",
      "('network', 7251)\n",
      "('tunnel', 7201)\n",
      "('capacity', 7117)\n",
      "('roof:shape', 7037)\n",
      "('ref:FR:FANTOIR', 6986)\n",
      "('website', 6788)\n",
      "('created_by', 6745)\n",
      "('cuisine', 6663)\n",
      "('start_date:FR:plantation', 6547)\n",
      "('phone', 6468)\n",
      "('junction', 6345)\n",
      "('backrest', 6344)\n",
      "('information', 6224)\n",
      "('public_transport', 6009)\n",
      "('wikipedia', 5956)\n",
      "('parking', 5929)\n",
      "('motor_vehicle', 5563)\n",
      "('description', 5370)\n",
      "('fire_hydrant:type', 5303)\n",
      "('area', 5291)\n",
      "('seats', 5207)\n",
      "('opening_hours', 5202)\n",
      "('usage', 5192)\n",
      "('entrance', 5174)\n",
      "('indoor', 5164)\n",
      "('source:maxspeed', 5106)\n",
      "('boundary', 5102)\n",
      "('waterway', 4927)\n",
      "('start_date', 4883)\n",
      "('covered', 4824)\n",
      "('school:FR', 4756)\n",
      "('sidewalk', 4744)\n",
      "('tracktype', 4700)\n",
      "('highway:cycle', 4685)\n",
      "('fire_hydrant:position', 4569)\n",
      "('admin_level', 4335)\n",
      "('tactile_paving', 4334)\n",
      "('importance', 4314)\n",
      "('building:part', 4140)\n",
      "('ref:UAI', 3941)\n",
      "('ref:NUM_ILOT', 3870)\n",
      "('material', 3712)\n",
      "('url', 3563)\n",
      "('ele', 3459)\n",
      "('bench', 3406)\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "import collections\n",
    "import operator\n",
    "\n",
    "tags = collections.defaultdict(int)\n",
    "i = 0\n",
    "nlines = 56825189    # number of lines in the osm file\n",
    "line_prog = [(1 + i) * nlines / 100 for i in xrange(100)]\n",
    "\n",
    "#Collecting and counting the tag k values\n",
    "for _, element in ET.iterparse('data\\\\paris_france.osm'):\n",
    "    i+=1\n",
    "    if i in line_prog:\n",
    "        print '{0:0.1f} % of original file has been processed'.format(100 * float(i)/nlines)\n",
    "\n",
    "    if element.tag == \"tag\":\n",
    "        for tag in element.iter('tag'):            \n",
    "            if tag.get('k'):\n",
    "                tags[tag.get('k')] += 1\n",
    "    element.clear()\n",
    "\n",
    "#Sorting the tags in descinding order\n",
    "#source : http://stackoverflow.com/questions/613183/sort-a-python-dictionary-by-value\n",
    "sorted_tags = sorted(tags.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "for i in xrange(100):\n",
    "    print sorted_tags[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, as expected, the majority of tags is related to traffic (highway, barrier, traffic calming, STIF, RATP, etc.), location (address, place, etc.) and usage (amenity, phone, tourism, opening hour).\n",
    "\n",
    "I used this list to select which tags I wanted to include in the MongoDB Database. The goal was to import only the most useful data in the database to limit the space needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Let's prepare our data for the MongoDB database\n",
    "\n",
    "The following code reads the OSM file and process it line by line to create JSON structures that can be implemented in a MongoDB database. The processed data is store in a JSON file on the disk.\n",
    "\n",
    "Only the most useful and frequent entries are kept. Some processing is done for all kind of elements, but some others are differenciated between nodes, ways, and relations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 % of original file has been processed\n",
      "2.0 % of original file has been processed\n",
      "3.0 % of original file has been processed\n",
      "4.0 % of original file has been processed\n",
      "5.0 % of original file has been processed\n",
      "6.0 % of original file has been processed\n",
      "7.0 % of original file has been processed\n",
      "8.0 % of original file has been processed\n",
      "9.0 % of original file has been processed\n",
      "10.0 % of original file has been processed\n",
      "11.0 % of original file has been processed\n",
      "12.0 % of original file has been processed\n",
      "13.0 % of original file has been processed\n",
      "14.0 % of original file has been processed\n",
      "15.0 % of original file has been processed\n",
      "16.0 % of original file has been processed\n",
      "17.0 % of original file has been processed\n",
      "18.0 % of original file has been processed\n",
      "19.0 % of original file has been processed\n",
      "20.0 % of original file has been processed\n",
      "21.0 % of original file has been processed\n",
      "22.0 % of original file has been processed\n",
      "23.0 % of original file has been processed\n",
      "24.0 % of original file has been processed\n",
      "25.0 % of original file has been processed\n",
      "26.0 % of original file has been processed\n",
      "27.0 % of original file has been processed\n",
      "28.0 % of original file has been processed\n",
      "29.0 % of original file has been processed\n",
      "30.0 % of original file has been processed\n",
      "31.0 % of original file has been processed\n",
      "32.0 % of original file has been processed\n",
      "33.0 % of original file has been processed\n",
      "34.0 % of original file has been processed\n",
      "35.0 % of original file has been processed\n",
      "36.0 % of original file has been processed\n",
      "37.0 % of original file has been processed\n",
      "38.0 % of original file has been processed\n",
      "39.0 % of original file has been processed\n",
      "40.0 % of original file has been processed\n",
      "41.0 % of original file has been processed\n",
      "42.0 % of original file has been processed\n",
      "43.0 % of original file has been processed\n",
      "44.0 % of original file has been processed\n",
      "45.0 % of original file has been processed\n",
      "46.0 % of original file has been processed\n",
      "47.0 % of original file has been processed\n",
      "48.0 % of original file has been processed\n",
      "49.0 % of original file has been processed\n",
      "50.0 % of original file has been processed\n",
      "51.0 % of original file has been processed\n",
      "52.0 % of original file has been processed\n",
      "53.0 % of original file has been processed\n",
      "54.0 % of original file has been processed\n",
      "55.0 % of original file has been processed\n",
      "56.0 % of original file has been processed\n",
      "57.0 % of original file has been processed\n",
      "58.0 % of original file has been processed\n",
      "59.0 % of original file has been processed\n",
      "60.0 % of original file has been processed\n",
      "61.0 % of original file has been processed\n",
      "62.0 % of original file has been processed\n",
      "63.0 % of original file has been processed\n",
      "64.0 % of original file has been processed\n",
      "65.0 % of original file has been processed\n",
      "66.0 % of original file has been processed\n",
      "67.0 % of original file has been processed\n",
      "68.0 % of original file has been processed\n",
      "69.0 % of original file has been processed\n",
      "70.0 % of original file has been processed\n",
      "71.0 % of original file has been processed\n",
      "72.0 % of original file has been processed\n",
      "73.0 % of original file has been processed\n",
      "74.0 % of original file has been processed\n",
      "75.0 % of original file has been processed\n",
      "76.0 % of original file has been processed\n",
      "77.0 % of original file has been processed\n",
      "78.0 % of original file has been processed\n",
      "79.0 % of original file has been processed\n",
      "80.0 % of original file has been processed\n",
      "81.0 % of original file has been processed\n",
      "82.0 % of original file has been processed\n",
      "83.0 % of original file has been processed\n",
      "84.0 % of original file has been processed\n",
      "85.0 % of original file has been processed\n",
      "86.0 % of original file has been processed\n",
      "87.0 % of original file has been processed\n",
      "88.0 % of original file has been processed\n",
      "89.0 % of original file has been processed\n",
      "90.0 % of original file has been processed\n",
      "91.0 % of original file has been processed\n",
      "92.0 % of original file has been processed\n",
      "93.0 % of original file has been processed\n",
      "94.0 % of original file has been processed\n",
      "95.0 % of original file has been processed\n",
      "96.0 % of original file has been processed\n",
      "97.0 % of original file has been processed\n",
      "98.0 % of original file has been processed\n",
      "99.0 % of original file has been processed\n",
      "100.0 % of original file has been processed\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "# the CREATED list selects the tags related to the \"created\" sub-dictionnary that will be imported in the json file.\n",
    "CREATED = [ 'version', 'changeset', 'timestamp', 'user', 'uid']\n",
    "\n",
    "# the INCLUDE list selects the tags that will be imported in the json file \n",
    "INCLUDE = ['name', 'place', 'population', 'railway', 'highway', 'amenity', \n",
    "           'crossing', 'exit_to', 'public_transport', 'traffic_calming', 'bicycle', 'foot', 'power', \n",
    "           'shop', 'tourism', 'bus', 'cuisine', 'train', 'opening_hours', 'subway', \n",
    "           'source', 'building', 'wall', 'natural', 'oneway', 'taxon:species','building:levels',\n",
    "           'genus', 'genus', 'circumference', 'height', 'maxspeed', 'operator', 'access',\n",
    "           'surface', 'barrier', 'service', 'layer', 'landuse', 'leisure', 'level', 'lanes', 'wheelchair', \n",
    "           'taxon:species:varietas', 'lit', 'sport', 'voltage', 'electrified', 'bridge', 'cycleway', 'shelter',\n",
    "           'frequency', 'emergency', 'network', 'tunnel', 'capacity', 'junction', 'parking', 'area', 'seats', 'usage',\n",
    "           'waterway', 'sidewalk', 'tracktype', 'tactile_paving', 'material', 'bench']\n",
    "\n",
    "def shape_geodata(key, value, node):\n",
    "    '''\n",
    "    This function creates a tuple with the geographical coordonates for future indexing\n",
    "    '''\n",
    "    if key == 'lon':    \n",
    "        try:\n",
    "            node['pos'][1] = float(value)\n",
    "        except KeyError:\n",
    "            node['pos'] = [None, None]\n",
    "            node['pos'][1] = float(value)\n",
    "    if key == 'lat':    \n",
    "        try:\n",
    "            node['pos'][0] = float(value)\n",
    "        except KeyError:\n",
    "            node['pos'] = [None, None]\n",
    "            node['pos'][0] = float(value)    \n",
    "    return node\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    node = {}\n",
    "    node['created'] = {}\n",
    "    \n",
    "    ### process for all elements ###\n",
    "    for key, value in element.attrib.items():\n",
    "        node['type'] = element.tag    # specifies the kind of element\n",
    "        if key in ['id', 'visible']: \n",
    "            node[key] = value\n",
    "        if key in CREATED:    # creating a specific subsection about data when the tag was created\n",
    "            node['created'][key] = value \n",
    "        \n",
    "    ### process if element type == \"node\" or \"way\" ###\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        for key, value in element.attrib.items():\n",
    "            if key in ['lat', 'lon']:    # creating a tuple with the geographical coordonates for future indexing\n",
    "                node = shape_geodata(key, value, node)\n",
    "        ## process for all sub-elements ##\n",
    "        for tag in element:\n",
    "            # if the k value is part of the INCLUDE list, it is included in the json Data\n",
    "            if tag.get('k') in INCLUDE:\n",
    "                node[tag.get('k')] = tag.get('v')            \n",
    "            # if the second level tag \"k\" value contains problematic characters, it should be ignored\n",
    "            if tag.get('k') != None and re.search(problemchars, tag.get('k')):\n",
    "                pass            \n",
    "            # if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "            # if there is a second \":\" that separates the type/direction of a street, the tag should be ignored\n",
    "            if tag.get('k') != None and re.match(\"addr:\", tag.get('k')):\n",
    "                if re.match('addr:.+:', tag.get('k')):\n",
    "                    pass                \n",
    "                else:\n",
    "                    try:\n",
    "                        node['address'][re.sub('addr:','',tag.get('k'))] = tag.get('v')   \n",
    "                    except KeyError:\n",
    "                        node['address'] = {}\n",
    "                        node['address'][re.sub('addr:','',tag.get('k'))] = tag.get('v')   \n",
    "            \n",
    "            # defining node reference as list ==> \"node_refs\": [\"305896090\", \"1719825889\"]\n",
    "            if tag.tag == 'nd':\n",
    "                try:\n",
    "                    node['node_refs'].append(tag.get('ref'))\n",
    "                except KeyError:\n",
    "                    node['node_refs'] = []\n",
    "                    node['node_refs'].append(tag.get('ref')) \n",
    "        return node\n",
    "                    \n",
    "    ### process if element type == 'relation' ###   \n",
    "    if element.tag == 'relation' :                       \n",
    "        ## process for all sub-elements ## \n",
    "        for tag in element:\n",
    "            if tag.tag == 'member':\n",
    "                try:\n",
    "                    node['members'].append({'type':tag.get('type'),'ref':tag.get('ref')})\n",
    "                except KeyError:\n",
    "                    node['members'] = []\n",
    "                    node['members'].append({'type':tag.get('type'),'ref':tag.get('ref')})                \n",
    "            if tag.tag == 'tag':\n",
    "                if tag.get('k') in INCLUDE:\n",
    "                    node[tag.get('k')] = tag.get('v')                          \n",
    "            # if the second level tag \"k\" value starts with \"addr:\", it should be added to a dictionary \"address\"\n",
    "            # if there is a second \":\" that separates the type/direction of a street, the tag should be ignored\n",
    "            if tag.get('k') != None and re.match(\"addr:\", tag.get('k')):\n",
    "                if re.match('addr:.+:', tag.get('k')):\n",
    "                    pass                \n",
    "                else:\n",
    "                    try:\n",
    "                        node['address'][re.sub('addr:','',tag.get('k'))] = tag.get('v')   \n",
    "                    except KeyError:\n",
    "                        node['address'] = {}\n",
    "                        node['address'][re.sub('addr:','',tag.get('k'))] = tag.get('v')                                     \n",
    "        return node\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def process_map(file_in):\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    \n",
    "    # trick to follow the file processing\n",
    "    i = 0\n",
    "    nlines = 56825189    # number of lines in the osm file\n",
    "    line_prog = [(1 + i) * nlines / 100 for i in xrange(100)]\n",
    "    \n",
    "    # file processing\n",
    "    with codecs.open(file_out, \"w\", 'utf-8') as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            i += 1\n",
    "            el = shape_element(element)\n",
    "            if i in line_prog:\n",
    "                print '{0:0.1f} % of original file has been processed'.format(100 * float(i)/nlines)\n",
    "            if el:\n",
    "                fo.write(json.dumps(el) + \"\\n\")\n",
    "                el.clear()\n",
    "                element.clear()\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_map('data\\\\paris_france.osm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems with Unicode encoding\n",
    "https://docs.python.org/2/howto/unicode.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Insertion in the MongoDB database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following code reads the JSON file line by line and import it in the MongoDB database.\n",
    "\n",
    "In order to avoid calling the database for each line, a temporary list is created to store a number of lines representing one hundredth of the JSON file. The list is then bulk imported in the MongoDB database and cleared to get new files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting the number of lines in the file...\n",
      "data\\paris_france.osm.json contains 21683305 lines.\n",
      "1.0 % of original file has been processed\n",
      "2.0 % of original file has been processed\n",
      "3.0 % of original file has been processed\n",
      "4.0 % of original file has been processed\n",
      "5.0 % of original file has been processed\n",
      "6.0 % of original file has been processed\n",
      "7.0 % of original file has been processed\n",
      "8.0 % of original file has been processed\n",
      "9.0 % of original file has been processed\n",
      "10.0 % of original file has been processed\n",
      "11.0 % of original file has been processed\n",
      "12.0 % of original file has been processed\n",
      "13.0 % of original file has been processed\n",
      "14.0 % of original file has been processed\n",
      "15.0 % of original file has been processed\n",
      "16.0 % of original file has been processed\n",
      "17.0 % of original file has been processed\n",
      "18.0 % of original file has been processed\n",
      "19.0 % of original file has been processed\n",
      "20.0 % of original file has been processed\n",
      "21.0 % of original file has been processed\n",
      "22.0 % of original file has been processed\n",
      "23.0 % of original file has been processed\n",
      "24.0 % of original file has been processed\n",
      "25.0 % of original file has been processed\n",
      "26.0 % of original file has been processed\n",
      "27.0 % of original file has been processed\n",
      "28.0 % of original file has been processed\n",
      "29.0 % of original file has been processed\n",
      "30.0 % of original file has been processed\n",
      "31.0 % of original file has been processed\n",
      "32.0 % of original file has been processed\n",
      "33.0 % of original file has been processed\n",
      "34.0 % of original file has been processed\n",
      "35.0 % of original file has been processed\n",
      "36.0 % of original file has been processed\n",
      "37.0 % of original file has been processed\n",
      "38.0 % of original file has been processed\n",
      "39.0 % of original file has been processed\n",
      "40.0 % of original file has been processed\n",
      "41.0 % of original file has been processed\n",
      "42.0 % of original file has been processed\n",
      "43.0 % of original file has been processed\n",
      "44.0 % of original file has been processed\n",
      "45.0 % of original file has been processed\n",
      "46.0 % of original file has been processed\n",
      "47.0 % of original file has been processed\n",
      "48.0 % of original file has been processed\n",
      "49.0 % of original file has been processed\n",
      "50.0 % of original file has been processed\n",
      "51.0 % of original file has been processed\n",
      "52.0 % of original file has been processed\n",
      "53.0 % of original file has been processed\n",
      "54.0 % of original file has been processed\n",
      "55.0 % of original file has been processed\n",
      "56.0 % of original file has been processed\n",
      "57.0 % of original file has been processed\n",
      "58.0 % of original file has been processed\n",
      "59.0 % of original file has been processed\n",
      "60.0 % of original file has been processed\n",
      "61.0 % of original file has been processed\n",
      "62.0 % of original file has been processed\n",
      "63.0 % of original file has been processed\n",
      "64.0 % of original file has been processed\n",
      "65.0 % of original file has been processed\n",
      "66.0 % of original file has been processed\n",
      "67.0 % of original file has been processed\n",
      "68.0 % of original file has been processed\n",
      "69.0 % of original file has been processed\n",
      "70.0 % of original file has been processed\n",
      "71.0 % of original file has been processed\n",
      "72.0 % of original file has been processed\n",
      "73.0 % of original file has been processed\n",
      "74.0 % of original file has been processed\n",
      "75.0 % of original file has been processed\n",
      "76.0 % of original file has been processed\n",
      "77.0 % of original file has been processed\n",
      "78.0 % of original file has been processed\n",
      "79.0 % of original file has been processed\n",
      "80.0 % of original file has been processed\n",
      "81.0 % of original file has been processed\n",
      "82.0 % of original file has been processed\n",
      "83.0 % of original file has been processed\n",
      "84.0 % of original file has been processed\n",
      "85.0 % of original file has been processed\n",
      "86.0 % of original file has been processed\n",
      "87.0 % of original file has been processed\n",
      "88.0 % of original file has been processed\n",
      "89.0 % of original file has been processed\n",
      "90.0 % of original file has been processed\n",
      "91.0 % of original file has been processed\n",
      "92.0 % of original file has been processed\n",
      "93.0 % of original file has been processed\n",
      "94.0 % of original file has been processed\n",
      "95.0 % of original file has been processed\n",
      "96.0 % of original file has been processed\n",
      "97.0 % of original file has been processed\n",
      "98.0 % of original file has been processed\n",
      "99.0 % of original file has been processed\n",
      "100.0 % of original file has been processed\n",
      "Number of elements\n",
      "21683305\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.maps\n",
    "db.paris.delete_many({})\n",
    "\n",
    "# insert the data into the MongoDB database\n",
    "def insert_data(data, db):\n",
    "    '''\n",
    "    This function insert the data object in the db MongoDB database in the 'paris' collection.\n",
    "    '''\n",
    "    db.paris.insert(data)\n",
    "    pass\n",
    "\n",
    "def num_lines(filename):\n",
    "    '''\n",
    "    This function opens the given file and returns the number of readable lines.\n",
    "    '''\n",
    "    print 'counting the number of lines in the file...'\n",
    "    i = 0\n",
    "    with codecs.open(filename) as f:\n",
    "        for line in f:\n",
    "            i += 1    # count of processed lines to follow the file processing\n",
    "\n",
    "    print '{0} contains {1} lines.'.format(filename, i)    \n",
    "    return i\n",
    "\n",
    "\n",
    "def insert_from_file(filename, db):\n",
    "    '''\n",
    "    This function insert json data from file to a MongoDB database.\n",
    "    The import in the db is done by grouping lines in a data buffer list.\n",
    "    '''\n",
    "    \n",
    "    # trick to follow the file processing\n",
    "    nlines = num_lines(filename)    # number of lines in the osm file\n",
    "    line_prog = [(1 + i) * nlines / 100 for i in xrange(100)]\n",
    "    \n",
    "    ### file processing ###\n",
    "    buffer_size = nlines / 100 # number of lines stored in the buffer before importing in the db\n",
    "    with codecs.open(filename) as f:\n",
    "        i1 = 0    # count of processed lines to follow the file processing\n",
    "        i2 = 0    # count of stored lines in the \"data\" list buffer before inserting them in the MongoDB database\n",
    "        data = [] # buffer list before importing in MongoDB\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "            if i2 == buffer_size:            \n",
    "                insert_data(data, db)\n",
    "                data = []\n",
    "                i2 = 0\n",
    "            if i1 in line_prog:\n",
    "                print '{0:0.1f} % of original file has been processed'.format(100 * float(i1)/nlines)\n",
    "        insert_data(data, db)\n",
    "\n",
    "                \n",
    "if __name__ == \"__main__\":\n",
    "    insert_from_file('data\\\\paris_france.osm.json', db)\n",
    "    print 'Number of elements'\n",
    "    print db.paris.find().count() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "['name', 'place', 'population', 'railway', 'highway', 'amenity', \n",
    "           'crossing', 'exit_to', 'public_transport', 'traffic_calming', 'bicycle', 'foot', 'power', \n",
    "           'shop', 'tourism', 'bus', 'cuisine', 'train', 'opening_hours', 'subway', \n",
    "           'source', 'building', 'wall', 'natural', 'oneway', 'taxon:species','building:levels',\n",
    "           'genus', 'genus', 'circumference', 'height', 'maxspeed', 'operator', 'access',\n",
    "           'surface', 'barrier', 'service', 'layer', 'landuse', 'leisure', 'level', 'lanes', 'wheelchair', \n",
    "           'taxon:species:varietas', 'lit', 'sport', 'voltage', 'electrified', 'bridge', 'cycleway', 'shelter',\n",
    "           'frequency', 'emergency', 'network', 'tunnel', 'capacity', 'junction', 'parking', 'area', 'seats', 'usage',\n",
    "           'waterway', 'sidewalk', 'tracktype', 'tactile_paving', 'material', 'bench']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do some analysis\n",
    "\n",
    "The goal of this chapter is to use the MongoDB tools to analize the newly created database and get more information about the OSM data. \n",
    "\n",
    "First, some questions related to data quality are studied in order to check if further data cleaning has to be performed. Then, other topics related to the OSM data related to Paris are studied. For instance :\n",
    "- Who are the most active contributors and how much did they contribute to the map?\n",
    "- What are the main amenities registered in the database?\n",
    "- What are the main cities in population around Paris?\n",
    "- What is are the cuisine types for the parisian restaurants?\n",
    "- What are the main traffic calming solutions implemented in the neigboring cities?\n",
    "- How many benches are registered in the database?\n",
    "- How many bridges are registered in the database?\n",
    "- What is the main kind of species registered in the database?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pprint\n",
    "\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client.maps\n",
    "\n",
    "### creating a pprint class to print unicode strings ###\n",
    "# source: http://stackoverflow.com/questions/10883399/unable-to-encode-decode-pprint-output\n",
    "class MyPrettyPrinter(pprint.PrettyPrinter):\n",
    "    def format(self, object, context, maxlevels, level):\n",
    "        if isinstance(object, unicode):\n",
    "            return (object.encode('utf8'), True, False)\n",
    "        return pprint.PrettyPrinter.format(self, object, context, maxlevels, level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###How does a single element look like ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{_id: ObjectId('5724d88d2c8cbf1d8c8e5f04'),\n",
      " address: {city: Saint-Cloud,\n",
      "           housenumber: 65,\n",
      "           postcode: 92210,\n",
      "           street: Quai Marcel Dassault},\n",
      " amenity: fuel,\n",
      " created: {changeset: 25039647,\n",
      "           timestamp: 2014-08-26T21:21:07Z,\n",
      "           uid: 178625,\n",
      "           user: bertrandmalen,\n",
      "           version: 6},\n",
      " id: 25209909,\n",
      " name: Station Total,\n",
      " operator: Total Access,\n",
      " pos: [48.8549783, 2.2224884],\n",
      " source: stations.gpl.online.fr,\n",
      " type: node}\n"
     ]
    }
   ],
   "source": [
    "MyPrettyPrinter().pprint(db.paris.find_one({'address.street': {'$exists':1}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The element structure seems to be conform to what is expected. All the important entries have been correctly imported in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###How big is the database ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris_france.osm: 4.1GiB\n",
      "paris_france.osm.json: 4.7GiB\n",
      "MongoDB database - storage size (with compression): 1.5GiB\n",
      "MongoDB database - data size (no compression): 5.1GiB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to convert byte size into human readable size\n",
    "def sizeof(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "root = 'data\\\\'\n",
    "files = ['paris_france.osm', 'paris_france.osm.json']\n",
    "\n",
    "for fi in files:\n",
    "    print fi+': '+sizeof(os.path.getsize(root+fi))\n",
    "db_stats = db.command(\"dbstats\")\n",
    "print 'MongoDB database - storage size (with compression): {}'.format(sizeof(db.command(\"dbstats\")['storageSize']))\n",
    "print 'MongoDB database - data size (no compression): {}'.format(sizeof(db.command(\"dbstats\")['dataSize']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries\n",
      "21683305\n",
      "Number of nodes\n",
      "18588534\n",
      "Number of ways\n",
      "3059389\n",
      "Number of relations\n",
      "35382\n"
     ]
    }
   ],
   "source": [
    "print 'Number of entries'\n",
    "print db.paris.find().count()\n",
    "print 'Number of nodes'\n",
    "print db.paris.find({\"type\":\"node\"}).count()\n",
    "print 'Number of ways'\n",
    "print db.paris.find({\"type\":\"way\"}).count()\n",
    "print 'Number of relations'\n",
    "print db.paris.find({\"type\":\"relation\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Who many unique users have contributed to this database ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6417 distinct users have contributed to the database.\n"
     ]
    }
   ],
   "source": [
    "print '{0} distinct users have contributed to the database.'.format(len(db.paris.distinct('created.user')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Who are the main contributors and how much did they contribute ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXwAAAFiCAYAAAD1O2MhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzsnXeYJFXVh99Z3AUBWYEFBQNB5IcEJUiQuKAEUVAQJShh\n",
       "CaKCElQUUTKIiphAkuQsAkpGyUGCCJKE34LCpxKXnFnYne+Pe3und5hQVV0907tz3uepp7tr+p46\n",
       "3VN96ta5J3R1d3cTBEEQzPyMGm4FgiAIgqEhDH4QBMEIIQx+EATBCCEMfhAEwQghDH4QBMEIIQx+\n",
       "EATBCKGtBl/SypKu6bVvK0l/bedxgyAIgrfzjnYJlrQX8BXg5aZ9ywHbt+uYQRAEQf+0c4b/ELAp\n",
       "0AUgaV7gEGD3xr4gCIJg6Gibwbd9PvAWgKRRwAnAnjTN+IMgCIKhY6gWbVcAFgOOBs4ClpR0xBAd\n",
       "OwiCIKCNPvxmbP8NWBpA0kLA2bb3HGzcyl/Yv3v2sfO/bf+rLzzFaT/eisUXX7x2XYMgCGYC+nSb\n",
       "D4XB712drauPfX0y+9j5mXPu9/X5N0nq7u6eWEGXVtcPWpXRCTp0ioxO0KFTZHSCDp0ioxN06BQZ\n",
       "degwjbYafNuPAKsOti8IgiBoP5F4FQRBMEIIgx8EQTBCCIMfBEEwQgiDHwRBMEIIgx8EQTBCGJI4\n",
       "/KBz6OrqGgMsbBtJLSUyNMl4pLu7e3I9GgZB0C66OrmJ+drb/7a7rzj8l597lGtP2iXi8CvQ1dW1\n",
       "+Eqb7ue+Etqq8OoLT3Hb+QcM+L+QNB74PXAfSfe5gH/fe++9Xxw9enSfn0PSB4CP2b5Y0i+AI2z/\n",
       "t4+3DvpdSJobuAqYZHv9ijKWBua2fUOv/dsCz9q+cDAZg1Dpf9r8PTXLkLQ+8EHgz8CRtjcqIu8v\n",
       "f/lL96677rogMBXY1/YuZXVq6CFpE+AnwK9tH1lmvKRdbR8laTtAtvcuo8Djjz/ePX78+I3y91KJ\n",
       "m2++uXu77ba7GXgTeArYxvZrkvYDNiSVjtk9J5b2RyfYi2nEDH8EMlBCW5voBq60vVVjh6Qzrr76\n",
       "atZfvy/7C8AnAQEX296jxeMvA/zb9mYtyNgMeByYzuDbPqUVxWpg2vfUvNP2FQCSFi4j7NRTTwWY\n",
       "y7aBKsa+mY2APSsa3R8CR1EwSbM3N998M8Bq9PpeynDAAQcAfM72JEmHAjtKuglY0/bK+WJ7HrBS\n",
       "1WMMNWHwg6Ggi6ZZiqQxwAJjx45tFNY7Dng/sABwIbAf8H1gttw74dvAzsCTwOnAu0jn7g+TXepB\n",
       "0reBzUmzr+uBHwG/BhaQtJ/tA5reuxZw8EorrcRtt912Qj7GV0izt3cCHyLNUP8CbAe8LukO4CTA\n",
       "wGTgAeCJ7N76MbA6MAvpjuQPkr4BbEOaMf/N9m699P0ssO/SSy/NvffeeyzwNeBTwEHA68AzpJLi\n",
       "ywHfA94AFgXOBg5r/p7y5zgHmIdUs+rDwDHAQpIuzfsvtH2opJOBs2xfIWmD/J2dO9dccwGcImlr\n",
       "4FTbn5C0bhF9bB/a9Lk2Bj4NrCDp6fxd7pbf/yDw1fxdb086N/azfTXA0UcfDTCPpCOBvwGrSLoC\n",
       "mA842vbxjf8dMAX4F7Cz7UaxxlkWWWQRgK2ygX40nwNT8mfYKf+PTgZeIZ13F9vet/l/c/rppzNu\n",
       "3LhJ+eXoPHY10l0Ttv8r6R2S5rX9TNNnfwRY3Pbkww8/nOOPP35b4FLgnPxZZwO+ZvsuSd8EtiRd\n",
       "2M62/Zv8v5kHmOfmm2/mE5/4xNW9x1GRWLQNhop1JF0j6T7g78D5q6yyCsAHgJttbwCsTDqhpwI/\n",
       "Bs60fRE9s7wfAlfYXgv4IqkC6zQkLZP3f8L2qiSDtx7J0Fzdy9h3kS40m5x22mmQjMJ2+VhzZRfI\n",
       "xsD3bT9GMvJH5Nv3OYADbW/ZkHfddddBWhtZA1gH2EfS2Cxzl6zP/ZJmadLhHcBvgA3PO+88SIbw\n",
       "A8CxwCa2xwPX5c/dTXLRbAqsAuzVx/dEfr4uybg1mD2PWxX4jKSPZnmN77UbwPalSyyxBKQL1JtN\n",
       "4wvp0/y/yC6uy4Hv5s+1P7B2/n6eJ11cu0nusDUaxh7g61//Onn/riRD92Z2xW1CKq8OcHyTTo3/\n",
       "XePYU3beeWeAM/LdxfH5fzAe+C1wRD72QqTzZUVg3dyvYxrjxo0DQNKmwFrAqSR35AtNb3sJGMv0\n",
       "TLsr6eqaNs9ZEXiadBHcBZhD0pLAl0gXkTWBz+c1sW7gKtur33PPPfQeRwuEwQ+Giqttrw2sQZoZ\n",
       "P5L3PwesKOl00g9x1rx/uruCzBKkWTvZCL/47LPPNv9dwC22G8buBmCpfvSZjzSzO3frrbeGdGFY\n",
       "KP/tH/nxf6RZVUOfZqa7tXjwwQchzWavAS4j3YEsDEwAdpV0bZbfLGcc8Jztp/NnOhx4DXjR9uN9\n",
       "fIZ7bE+1/Wp+X0OvZpnT3/IkbrP9er5A/A3ovVjfrx2QNK6kPr3pAhYB7rP9St53fZOMvvTtzR35\n",
       "8UlgdknT/nf5+16PdPGZRq+1yQVs392H/rfYfjWfL7fy9u8FSXsAewAb2H4DeJF0h9ngXaQLWJ80\n",
       "6XEZcBPwJ+BA0h3f0qRz4mrgStKs/sP5/RMB1lxzTfoYV5mB/tEPF9j+3crBg5GH7WdJt/K/mzRp\n",
       "EqSZ2fO2v0Iy+LPnt07h7efn/aSZEJLeB8z97ne/u/nvDwArS5olz+DXpH+D8jTJoG+cZ/iHkX50\n",
       "0LffeArJDdBguh/eoosuCnBNvqitC5xLcjXsRLprGU9yg3yiadhTwLvzojJ5cXoRYC5J783vWavp\n",
       "M/SnV/P31NCr+SLwMUmz5juKVYB7Se6JBfPfl2+8cdSoUTR/znwxKqNPb7qBh0kl0Rv/2/FNMvoz\n",
       "YM369z7O08B/gY3z9938v+vrczyW7/566/8xSaPzXddKwD3NMrJraXVg3XzeQjK+60vqkvRBYFTT\n",
       "3xq8Diwoqev+++9v7BsPPJ7vVA4BDiWdr/fZXjt/jtOAxoVpKsCtt95KH+MqM5AP/zXSbcRAK8SX\n",
       "tHLwYHh49YWnhlpWs/sA2/dL+vXBBx98COmHeqakFYD/A26XtADpx7dP9pk3xh8KnChpM5KPfadR\n",
       "o0Zd0ST3Xkm/J/0oRwE32P5T9vdOZzRsT5W0G3DpFltsAcmnvC1pVt783sbzvwM/k3R/b1lA9zrr\n",
       "rAPwsqTrgTmB822/LOke4AZJL5EuMLf20uEbwCVbbbUVJONxm6SdgPMlTQWeJV0Ul+lHr3sb39PK\n",
       "K6/c33f+AmmGODdwmu0HJP0uf5dfJs0muwGWW245brnlllPocblAumgV1edt2H4mR7Zck2U8SPL/\n",
       "bzHAuH9KOo10fkx3HNvdjf9dXgN6geSGmoYkgM9J+nvW/8g8CXgT2IGeqr0XAfOS1jP+2TT+PaNH\n",
       "j4Z0J3FZlne27WMl3QDcTDrHvtGH7j8l+ewfyROSbuAu4GxJXyfZ3QNs3y3pKkk3ku4kbyG5pxpj\n",
       "yC62HZvH9fN9FaLfsExJq9u+sY/9c9l+caD31EWEZdYvoykO38pncVWaZFSNw++E/0enyOgEHTpF\n",
       "Rtt1yNFLvxkkXHVm+S6m0e8Mv2HIJW1E8rseBNwGzJ+jHY5sp7EP2kM2zBPz87IXzL7ktSwjCIaB\n",
       "6e46RwpFFm33A04khW3dRlpkmNBOpYIgCNqJ7f+zvfFw6zHUFIrSsf0A8BngItsvk2JSgyAIghmI\n",
       "Igb/yZwAsSJwuaSfA/9pr1pBEARB3RQx+FuSXDnj8+z+wbwvCIIgmIEY1ODniJwpwARJcwKv2X6p\n",
       "7ZoFQRAEtTKowZf0E1I8/qYk3/12ko5ot2JBEARBvRRx6axPSmp43fZzpCzCT7dVqyAIgqB2ihj8\n",
       "Kb1ez9rHviAIgqDDKWLwzyWVYp0nFxK6gVR6NQiCIJiBGLQevu3Dcr3s/5BKt+5btKGBpJWBw2yv\n",
       "LWlZempSv0HqHlNfUZcgCIJgQAaqlrl8flyLVEjtIlIBppckrTmYYEl7kepQN8rd/hLYNVeFO59U\n",
       "PCkIgiAYIgaa4X+dVGXuAPquObH2ILIfIkX2nJZfb2H7ifx8NP3Xzw6CIAjawEDF03bKT8+xfXRZ\n",
       "wbbPV1M/zYaxl7QqqXPLGmVlBkEQBNUpsmi7a10Hk7Q5cDSwYXMPyCAIgqD9FGli/l9JV5MaN7ye\n",
       "93XbPrDMgSR9hdRkYnyO528J9+5eXZw6SqK2KqMTdOgUGZ2gQ6fI6AQdOkVGJ+jQKTKqjO+zhn4R\n",
       "g39Lr4OWLcbfnbvS/IrU0ej83HfjOtv7l5Q1DUnRAGXGl9EJOnSKjE7QoVNkdIIOnSJjaBqgNPGI\n",
       "7ZObd0gq5Oax/Qiwan45bynNgiAIglrp1+DnJKu5gK/lZr2NHpCjgS8DRw6JhkEQBEEtDLRo+xDJ\n",
       "yDdvo0h+/G3br1oQBEFQJwOFZV4EXCTpHNv3D6FOQRAEQRso4sNfSNJpwDz0LB502160fWoFQRAE\n",
       "dVPE4P8G2AO4jxHY5T0IgmBmoYjBn1S0WFoQBEHQuRQx+DfkDleX05N4he3r26ZVEARBUDtFDP7K\n",
       "JFfOcr32D1Y8LQiCIOggitTDHz8EegRBEARtZlCDnyteHg8sAqwJnAFsb/vh9qoWBEEQ1EmRapnH\n",
       "AocDLwFPkAz+Ke1UKgiCIKifIgZ/nO0rAGxPtf07YGx71QqCIAjqpojBf1XS+xsvJK1OU7ROJ9PV\n",
       "1TWmq6tr8cY2ceJEml6PGW79giAIhpIiUTp7ApcAi0q6i5Rx+8W2alUfC6+06X6efez8AOx82JWM\n",
       "n3CUX33hKW47/wABZcsrB0EQzLAUidL5m6QVgcWBWYAHbL/Rds1qYvax8zPn3O8bbjWCIAiGnSIz\n",
       "fGxPBu5tsy5BEARBGyniww+CIAhmAsLgB0EQjBAG6nh10gDjum1v3wZ9giAIgjYxkA//OvpvoBtl\n",
       "koMgCGYwBjL41wzwtzD4QRAEMxhFZvj9sUjNugRBEARtZKCetgsPoR5BEARBmylSLXMJ4BvAHCR/\n",
       "/juAhW2v2WbdgiAIghopknh1DvBHYHXgZGBD4LIiwiWtDBxme21Ji+XxU0lJXLvYjrWAIAiCIaJI\n",
       "HP4o2/sBVwB3AJ8D1h9skKS9SHX0Z827jgB+kO8MurKcIAiCYIgoYvBfkTQrqdDYCrmOzrgC4x4C\n",
       "NqUnrHP5pj64lwGfKqtsEARBUJ0iBv904OK8fUvS5cBjgw2yfT7wVtOu5nj+l4ma+kEQBENKEYN/\n",
       "A7Cp7UnAeOA4YJMKx5ra9PxdwPMVZEzDtklho/1u+T2Vx/ezUXFcXeNnJhmdoEOnyOgEHTpFRifo\n",
       "0Ckyqo7vkyIG/xzbLwHY/q/t822/UmBcb+6UtFZ+/mng+oHePBiSRLpr6HfL76k8vp+NiuPqGj8z\n",
       "yegEHTpFRifo0CkyOkGHTpFRdXyfFInSuU/SvsCtwGuNnU3++MFoXG2+DRwvaQzwT+APBccHQRAE\n",
       "NVDE4M8LrJ23Znq/fhu2HwFWzc8fJLmEgiAIgmGgSMer8UOgRxAEQdBmimTaLkyKp18EWBM4A9je\n",
       "9sPtVS0IgiCokyKLtscChwMvAU+QDP4p7VQqCIIgqJ8iBn+c7SsAbE+1/Tsihj4IgmCGo4jBf1XS\n",
       "+xsvJK0OvN4+lYIgCIJ2UCRKZ0/gEmBRSXcB8wBfbKtWQRAEQe0UMfgPAx8HBMwCPJDr6QRBEAQz\n",
       "EEVcOncCFwBLkyoShLEPgiCYASli8BcGfgWsB1jSyZKi0mUQBMEMRpHEqynAX4C/SFob+DlwPjBX\n",
       "m3ULgiAIaqRI4tUKwBak2vYTSTH5f2yzXkEQBEHNFFm0PR44FVjV9pNt1icIgiBoE4P68G0vD1wF\n",
       "fEnS7pKWbb9aQRAEQd0MavAlbU1y4SxCWsC9QNIObdYrCIIgqJkiLp3vACvZfgZA0sHAdcAJ7VQs\n",
       "CIIgqJciYZmjGsYewPbTwJT2qRQEQRC0gyIz/Lsl/ZI0o+8CdgDuaqtWQRAEQe0UmeHvBEwGTgRO\n",
       "ys+/0U6lgiAIgvopknj1KrDXEOgSBEEQtJEiM/wgCIJgJqBfgy9pzqFUpBPp6uoa09XVtXjzNnHi\n",
       "RJpejxluHYMgCIoykEvnGmBFSb+1PVJ99guvtOl+nn3s/NN27HzYlYyfcJRffeEpbjv/AJHKTQRB\n",
       "EHQ8Axn8d0k6A9hA0mykCJ0G3ba3b69qncHsY+dnzrnfN9xqBEEQtMxABn89YDywOinRqgvobnoM\n",
       "giAIZiD6Nfi2/wOcmtsa3k9Px6t7bb9V5WCSRgG/AxYHpgI72XYVWUEQBEE5ikTpjCb5qU8hxeH/\n",
       "R9IqFY+3HjCH7dWBA4FDKsoJgiAISlIk0/bXwOa2bwXIxv7XwEoVjvcaMFZSFzCWlMQVBEEQDAFF\n",
       "ZvhzNIw9gO1bgNkqHu+mPPYB4FjgNxXlBEEQBCUpYvCfk/T5xgtJmwDPDPD+gdgLuMm2gGWBUyRV\n",
       "imXPvv/ugbaB1gdaHV9URh8bFcbMrDI6QYdOkdEJOnSKjE7QoVNkVB3fJ0UM/leBH0h6RtKzwA+A\n",
       "rxUY1xdzAC/m58+R1gdmqSJIkkgRQ/1u+T1tGV9URh8bFcbMrDI6QYdOkdEJOnSKjE7QoVNkVB3f\n",
       "J0Vq6UwEVsqZt6NsvzjYmAH4GXCSpBtIxn5v26+1IC8IgiAoSJFFWwBsv9zqwWw/D2zSqpwgCIKg\n",
       "PFE8LQiCYIQQBj8IgmCEUNilI2ll4AhSWOUBti9sm1ZBEARB7QxUHrl3uOQPgE2BTwOHtlOpIAiC\n",
       "oH4GcumcL2nrptcvAhOAbYCX2qpVEARBUDsDGfyNgdGSLpG0Pin2/nngDeBzQ6FcEARBUB8DVcuc\n",
       "Cpwo6UxgT2Bn4GDbdwyVckEQBEF9DOTD/4Sk84ATgT+SMm63kXSypEWGSsEgCIKgHgaK0jkG2IFU\n",
       "DuFY22sAu0v6EKm08dYDjA2CIAg6jIEMfjewMPBOYFrDE9v/Iox9EATBDMdAi7abA6sBS5Eic4Ig\n",
       "CIIZmIFm+Ova3mOgwZJ2tX1kzToFQRAEbWAgg/9dSY3KmL3LbXbnfd8FwuAHQRDMAAxk8K8B1h5k\n",
       "/NU16hIEQRC0kYHi8LcbQj2CIAiCNlO4eFpQja6urjGkaCcAbCNp8aa3PNLd3R3N3IMgaDth8NvP\n",
       "wittup9nHzs/ADsfdiXjJxxlgFdfeIrbzj9AwMThVDAIgpFBGPwhYPax8zPn3O8bbjWCIBjhDGrw\n",
       "JW0AHAzMQ0+0TrftRdupWBAEQVAvRWb4vwH2AO4jhWMGQRAEMyBFDP4k2xe3XZMgCIKgrRQx+DdI\n",
       "OgK4HHi9sdP29W3TKgiCIKidIgZ/ZZIrZ7le+wdLygqCIAg6iEENvu3xAJLmAmax/Vy7lQqCIAjq\n",
       "p0iUzoeAs4DFgC5JjwCb264UOy5pb2AjYDRwpO1TqsgJgiAIyjFQeeQGxwI/tT2P7bmBHwPHVTmY\n",
       "pPHAJ2yvCowHIrQzCIJgiChi8MfZ/kPjhe3fA/NWPN56wD2S/ghcBFxYUU4QBEFQkiIG/3VJKzRe\n",
       "SPo48ErF480HrABsBnwNOKOinCAIgqAkRQz+7sB5ku6QdAdwXt5XhaeBP9t+K68BvC5pXBVBtk2K\n",
       "Hup3y+9py/ihlNHHRoUxnSijE3ToFBmdoEOnyOgEHTpFRtXxfTKowbd9C/BhUh/bbYEP531VuBHY\n",
       "AEDSgqQG6c9UESRJpFIP/W75PW0ZP5Qy+tioMKYTZXSCDp0ioxN06BQZnaBDp8ioOr5P+o3SkXSA\n",
       "7f0knUS6YnQ1/a3b9vb9je0P25dIWlPSbaSLzTds93s1CoIgCOpjoLDM2/PjdX38rbKRtv29qmOD\n",
       "IAiC6gzU8eqi/HRB24c2/03Sj9uqVTAd0UQlCII6GMilcxjwHmBjSYvR49J5B7AKsHf71Qsy0UQl\n",
       "CIKWGcilcz6wJPBJklunYfDfAg5ss15BL6KJShAErTKQS+c24DZJF9h+YQh1CoIgCNpAkWqZz/UR\n",
       "WfiY7fe3QZ8gCIKgTRSpljktVl/SaODzwKrtVCoIgiConyKZttOw/abtc4F12qRPEARB0CaKlEfe\n",
       "tullF7AU8EbbNArawiChnRHWGQQjgCI+/LWZvqbD08DmbdMoaBd9hnZGWGcQjByK+PC3g2kdr960\n",
       "/Vq7lQraQ4R2BsHIpohLZ0ngZOBD+fX9wLa2/9Ve1YIgCII6KbJoezywv+15bc8L/Bw4ob1qBUEQ\n",
       "BHVTxOC/0/aljRe2LwDGtk+lIAiCoB0MVEtnHlJUzh2S9gB+B0wBvgxcPzTqBUEQBHUxkA//Dnqi\n",
       "cz4JfCs/78r7d2ujXkEQBEHNDFRLZ+Eh1CMIgiBoMwO5dPa3vX9fHa+ASh2vgiAIguFjIJfO3/Pj\n",
       "tflxOoPfFm2CIAiCtlGk49VXbK87RPoEQRAEbaJIWOZskj7Ydk2CIAiCtlKkls58wCOSngIaZRW6\n",
       "bS/aPrWCIAiCuili8Ndnev89hA8/CIJghqOIwT/C9head0i6ihSbHwRBEMwgDBSWeQGwLLCgpId7\n",
       "jflPuxULgiAI6mWgGf52wNzAr4Fv0uPWeQt4opWDSpqfFPb5SdtRhz0IgmAIGCgs8wXgBWBjSUsB\n",
       "jdo6AItSsZ5O7ot7LPBKlfHB8NC7YxZE16wgmNEoUg//KGAj4N9Mv1i7dsVj/gw4Gti74vhgeJiu\n",
       "YxZE16wgmNEosmi7HqA6Ol1J2g6YZPvPkvbm7dE/QQcTHbOCYMamSOLVvwu+rwgTgHUlXUNaED5F\n",
       "0nuqCLJt0h1Hv1t+T1vGz0wyhkqHPjYqjJlZZXSCDp0ioxN06BQZVcf3SRFD/hzwT0lnSTopbycW\n",
       "GPc2bK9le7zttYF/ANvYfrKKLEki3SH0u+X3tGX8zCRjqHToY6PCmJlVRifo0CkyOkGHTpFRdXyf\n",
       "FHHpXJ63xlWjiwGuIEEQBEFnMqjBt32ypGWA8fn919j+R6sHzrP8IAiCYIgY1KUjaWvgj8AiwELA\n",
       "BZJ2aLdiQRAEQb0Ucel8B1jJ9jMAkg4GrgNOaKdiQRAEQb0UWbQd1TD2ALafJjUzD4IgCGYgiszw\n",
       "75b0S9KMvgvYAbirrVoFQRAEtVNkhr8TMBk4ETgpP/9GO5UKZk66urrGdHV1Ld7YJk6cSPPrXL4h\n",
       "CII2UWSGPxm4yfZekuYDNgZebq9awUzKdOUZGqUZAKI8QxC0nyIG/3hgFuBPpPj7dYCVgJ3bqFcw\n",
       "kxLlGYJg+Chi8Fe0vTRMW7D9sqR72qtWEARBUDdFfPhdkhZsvMi1byJKJwiCYAajyAz/EOAOSTeS\n",
       "onRWBnZrq1ZBEARB7Qw6w7d9JrACcDZwCikJ67x2KxYEQRDUS5EZPrYfBf7QZl2CIAiCNlJXnfsg\n",
       "CIKgwwmDHwRBMEIo0tN2MWAV4EzgGGB5YA/bN7RZtyAIgqBGiszwG+UUNgYWB/YEDm+nUkEQBEH9\n",
       "FDH4s9n+PfBZ4Ezb11NwsTcIgiDoHIoY/LckbUYy+BdL+jyReBUEQTDDUcTg7wxsCOxi+zHgS8CO\n",
       "bdUqCIIgqJ0iiVd3AwcBr0saDfww7wuCIAhmIIr0tN0CuBD4NTAvcFPucxsEQRDMQBRx6XwPWA14\n",
       "0fYTpLDMvduqVRAEQVA7RQz+FNsvNl7YfpxYtA2CIJjhKBJeeZ+kbwJjJC1Lam/4j/aqFQRBENRN\n",
       "EYO/C/BD4DVSX9urgW9XOVhe9D0RWAiYFTjY9kVVZAVBEATlGNTg234Z+H5Nx/syMMn21pLmJt0p\n",
       "hMEPgiAYAvo1+JLutL2cpKl9/Lnb9iwVjncuPWWWRwFvVZARBEEQVKBfg297ufx0Odt31XEw268A\n",
       "SHoXyfjvU4fcYOTQ1dU1Bli48do2khbPLx/p7u6ePCyKBcEMQJEonbPrPKCkD5DWAU61XVm2bQPd\n",
       "A235PW0ZPzPJ6AQdSsh4Y6VN9/P4CUd5/ISjvPNhVzJ+wlFeadP9bPuNwcYD3ZMnT+6eOHFi80bj\n",
       "+eTJkwcd389GxXF1jZ+ZZHSCDp0io+r4Pili8P8paV9J60taU9JaktYsMO5t5Abofwb2sn1yFRlN\n",
       "skTqsdvvlt/TlvEzk4xO0KGMjNnHzs+cc79vum32sfMXGg90zTrrrNp67zPZ+bArp9u23vtMZp11\n",
       "1kFldHV1zdrV1aXmbeLEiTS9nrWIHr02KoyZWWV0gg6dIqPq+D4pEqUzL7B23prp/boIPwDGAvtK\n",
       "2jfv+7Tt1yvICoLKNC4aFVl4pU338+xj55+2o3Gn8eoLT3Hb+QcImDiQgEFcUxDuqaANFDH4u9q+\n",
       "t3mHpE9UOZjt3YDdqowNgk6ixQsG9LpoNC4YAEUvGkFQloGidFYHZgGOl9RcHXM0cDSpGUoQBBVp\n",
       "9aIRC9hBWQaa4a8LrAksABzQtP8t4Nh2KhUEQSH6vEuo6laCuGjM7AwUlrkfgKRtbJ86dCoFQVCU\n",
       "4V6LCGYsivjwr5d0ODAPPau/3ba3b59aQRAMBTWsRQQzEEUM/u+B6/PWoN84zyAIgqAzKWLw32H7\n",
       "O23XJAiCIGgrRRKvbpS0saQxbdcmCIIgaBtFZvhfBHYFaEqUrFo8LQiCmYiI9JmxKFIeeYGhUCQI\n",
       "ghmSyDqegRgo8errto/Oz5eyfV/T335pe/ehUDAIgs4mso5nHAaa4X+VlFELcDqwXNPf1mqbRkEQ\n",
       "jDgiPHRoKLJoGwRB0NF0dXWN6erqWryx5eqljdcRcJIpsmgbBEHQ6bRUZmKkEAY/CIKZglbcQiMl\n",
       "2mggg7+UpIfz8wWbngMs2EadgiAIhprao42g8y4aAxn8KH8cBMGIoe5oI+i8ENWBqmU+UlVoEATB\n",
       "SKTTQ1TDhx8EQdBBtDNENcIygyAIRghh8IMgCEYIYfCDIAhGCGHwgyAIRghh8IMgCEYIQxqlI2kU\n",
       "8Fvgo8AbwI62/zWUOgRBEIxUhnqG/3lgjO1Vge8DPx/i4wdBEIxYhtrgrwZcDmD7VuDjQ3z8IAiC\n",
       "EctQG/y5gBebXk/Jbp4gCIKgzQx1pu2LwLuaXo+yPbW/N7/6wlOl9hd9b6vjZyYZnaBDHTLKjK9D\n",
       "xszyXXRlWT+1AAAgAElEQVTy56hDRifoMBwy+qOru7u7ZSFFkbQpsJHtCZJWAX5k+zNDpkAQBMEI\n",
       "Zqhn+BcA60q6Kb+eMMTHD4IgGLEM6Qw/CIIgGD5iwTQIgmCEEAY/CIJghBAGPwiCYIQQBj8IgmCE\n",
       "EB2vgqAikuYHZmu8tv2fYVQnmEmQtBDQHE3zJvC07Tdbld2xBl/SssCngLHA88D1tv9WUsaAiV2D\n",
       "jF0YWBq4GvgeqQzEvcChtl8oKGMr22f22jcbcJTtHUrqs6Pt3zW9/pbtXxcYdwbQlbdmum1vVUaH\n",
       "LG8+UoP7+20/W2LczqSTuC89jiupw5G2d216fartbQrq0BdVdPgtsCHweNPuT5QY3/L5neV81/bP\n",
       "yo5rGr9fr13dtg+sIGdxYDHgbuCxKr+7nHU/Dphku3T4oKQxtis3+G6S8wPbh5YcswHwEeBPwEmk\n",
       "38j/AV+z/Y+SKlwEfAB4IMt5FXiHpL1sn1ZS1nR0pEtH0r7AIcBk4N/AW8D+kg4qKeqKFtQ4FXgZ\n",
       "+FU+/j7AY8CZAw3qxV6SNm68kCTgNqDwj0HSlpLOAg6RdFbezgG+VlDEH4DlgGP72IrqcEl+/Axw\n",
       "E/At4AZJGxWVASwB7AW8t9e2QAk9dpX0OLCTpMfz9gTw/oIiFujj+KV0aGIlYFHbn2hsRQfWeH4D\n",
       "bCiplYnbk8ATwFOk73GhsgIkfRM4mvSZvgQMOhHpQ8bnSd/Fn4GJkj5ZVgZwu6RfSlq6wthm1q0w\n",
       "5kDgHOA3pITSBYCdSd9LWR4GPpzPqcVINmNp4JsVZE1Hp87w17O9evMOSb8GbgV+VELOs5I+B5hs\n",
       "ZG0X7fjebftaSfvY3inv+4ekL5U4/gbAFZJeBt4DHAbsafu8EjIuJ80ixwHHkGbIU4BCZaVtXyBp\n",
       "PDC/7d+XOG4zs+fH7wOr2Z4kac6s20UF9dhD0hLAZbZvq6KE7SOBI/P/5JAKIk6w/d984W2VfwHv\n",
       "BF6pMLau8xvSefGYpIdJ53h3rkZbCNvH9NLj8pLHB9gCWBO40vYRkm6vIGN/YBXbT0h6D+m8Wqmk\n",
       "jOVIv7n98p3oGcBZtl8uKaf3XWgRJtt+TFK37esBbN9V8VR7r+2ns4znJL3X9jOSplQR1kynGvx3\n",
       "SFrE9sNN+xYhGboyvAfYvde+tQuOfV7SZsClkrYFLgQ+Q4kfeD55NwSuJN0trGb7f0XHZxnPAddK\n",
       "uo5UfG4qsAnJvVRUxm5ljtkHo/Pj88AzWebLkmYpKWcbYI4WdYFk9H8GLEW6mB9U0L20J7AH6e6m\n",
       "t8ug6HnR4IPA/0l6KMsqY2jrOr8BNuLtn6Uw2RXTYEHS5ypLF9Pftb5eQcbTtp8AsP2kpBcHG9Ab\n",
       "21MkXZZ12QnYFdhO0tm2f1NCVJVyL3+XdBTwV0knAJeQXH7/rCjrbOBmkpvwTkmbk+7GWqJTDf7u\n",
       "wAWSxtBTcG0yxd0YANgeL2kssDDwr5JX+p2AnwKr5vGHATcCOxYVkPWfBHwOOBeYX9JTWbeyvsaz\n",
       "gYuzPl0ko79JQT3mJ504swNPA7fYfqnEsZ+RdB/wbmA3SceSPs9NAw+bHtuTgEnZV7sA8HjFNZYT\n",
       "getI7rW1gJOBjQcakI+/R34cX+GYvdmS6oa2lvM78xbp3Jyf5FK4l+Q7Lspx9HyO14FvV9DhLOB6\n",
       "YKFscP9YQcbTkn4PXAWsCIyW9G3ShfSIIgIk/ZTUc+M64DDbt+Vz7e8kV8tg4/cjXSTeyjPzbtsL\n",
       "FtR/T2BrYD3SXdcXSfbi+ILjm9mFdD4vAZxm+5J8V1robnogOrq0gqR3kRa1XrRd+oqfZ+j7kC5s\n",
       "5wJTbR9cUZfZ8/jCsxdJj9DzY+pqeo7tRUoe/wbba0i6Nl/IrrT9qQLjtiR9B/eSLha3AksCe9m+\n",
       "pKQO8wNjSD7fT9ouvEYi6QTbO0hamXSr/QzpjmWC7VtK6nFts9GWdGNvF8kg4x8l3f1NIv04XyPN\n",
       "nnax/eeCMt5PL0ObezwUptXzO8u4lNRI6EckY3WC7ZWryGoFSUuS77hs311h/Hb0cwG1fUpBGTvR\n",
       "hwtH0sK2Hykw/nZgDduvFTleH+Pny+7ODwPLAvfZLj3DlzQX8Gl6IsC6bZ9aRafedOQMX6mS5lGk\n",
       "H+Letm/I+y+wXWhWm9mTNLO9DDiUtPhRyOBLWoq0CPUcyUD9jlS/f3fbRf3WC5fQdTBGK1UbvS/7\n",
       "J9812IDMN4EVbL8haV7STGdV0oJ2YYOfF9XWoucuoZBhbGLR/Hgo8GnbD0pakHTnsmZJWbNJWsD2\n",
       "45LeS/ngg+uB/W1b0oeA/YCDgNMp/rmOo8fQ3gqcABQytDWe3wDvtH2VpB/avldSKWPVPKvNu8rM\n",
       "ahsyPkhyLc0GLCnp8xUifc4gz+xJk6MFe0e4DXD8nWwfTzrH9unlN59MOtcfKSDqKXq+h1LkNZhH\n",
       "c1DB7qRz7NuSzqsQRfUn4FHgv1V0GYiONPjAEaRb5tHAaZL2zrPJd5eUM8X265Kw/VZePC3KMcAP\n",
       "Se6c80jhUa9RYqGygaTlgK8y/RV7+zIySO6lLUgXsW+SDFQRZqNn5vQG8EHbL6hE45l8q7wA8FeS\n",
       "X/JFYA9Jq5UNXwPesv0gQF7kKjkcSEb2puznnYvkfivDB2w76/AvSQvlC1CZOOdWDG1d5zfAa0oh\n",
       "gbNI+gTl/ecbkc6JSrPazLnAX2jNQF1AskfvJ13A76B4RFwj/8G8/S5hDGnNZpn+BitFwUG6W7tT\n",
       "0r30rMsUDV1e0fa3JF1Pukt4RSl66hagrMHvsv2VkmMK0akGf3Ijmqax6CnpsQpybsz/zPdlv3OZ\n",
       "OOcu29cB10la2/aTWZ8qyQ8nk2bWjQXb0n402+fnE/GjJL/gowWHng7cJula0kz6SEm7k/yaRVnN\n",
       "9moAko4jrSVsSDqZixr8sZLuAGaXtANpRvdzyvmbAbD9lzwzn7cRzVCSxyUdRs+i2OOS1iXNBovS\n",
       "iqGt6/yGFPp3OMk19R3g6yXHV57VNvGi7R+2KGOc7VUk/Y4U9nt6ibGvS1qLFM44HbavkzRYoEQj\n",
       "RLmvPJHCSJqHFFo6Bym4Y2xFUXfnu8A7s05V1vz6pFMN/kuSvgUclyNdtiTNIsaUEWJ7b0mfJn1x\n",
       "9xd1xWQm5pNvZ9vbAUjam+S/LsvjbkqaqoJSrPPngXmA00i3r7sOOAjIYXJ/JiWFHGP7AUnjShrK\n",
       "WZv8oIsBs5LOndEDjppej+WVks4+SkokmUpK0jmhqIzsOvguyd/+J+B8SaNJyS1lwgm3Jd0VbEBa\n",
       "29ifFNK3ZQkZDUM7L+UNbcvnt6TRTpmXT5KinxoUmkzUNKttcK+kLZjeQBUNf27wiqQuYE7br0oa\n",
       "V2LsZvlx2Xz8m0ghnW8C19m+bJDxNwKzkBaft8j7ZgEuBa4tqMOBpMXie4C7JP2NFDu/d8HxzYwn\n",
       "3Xk16KbHJdoSnWrwv0IKn5sVeN32Pdl/XTb7bUvbZwGXSVpA0uW2Nyg4fCfgs7abQ+X+B/yyjA6Z\n",
       "RyR9n/SDgPSjKusDrxzrnF0OswDz5JnDoZIOtX1lQRHfI4WGPk/y4W8N/AD4bZkPkN1rh9huJLYU\n",
       "Tv7KnEq6M5iH5CPdlPQ/OY3kaivKH22v12vfzSV12cP25iXHNKjj/D6VdIGayPRGvqhxaISmNma0\n",
       "rURvLEcyts2UDXO9gOSqu0vSLZQLf/4mTMsh2ND21HzxKPob255kmN9LcgtBmpDcUEKHyyTdSFof\n",
       "u5gUlHBHjkwrhe2PNr/Oi8C10JEGP/uYDwU+qhRW+RwpCuLzJUVtI+klkh/7ENLiXFEdpgB/yjPI\n",
       "FUnf1X9Js+yzBhrbB7MByluDsga/1VjnY0jhXgeSonZ+SsoPGJTsq16U6dPep0WkSPqaeyXwDEAr\n",
       "yXCj8uIckjazfU1+XibEFOC5FnRosKSkuZ3yJEpRx/ltu3E38nmXT93H9rUwLdpoLMmt8z0qZMm6\n",
       "hjBX20dK6rLdLeli4KEKYuYnzcynkn5z8xQ89nHAcZK2t31iheM25Lwk6X7ShfjDwCpKiVilS1X0\n",
       "4gzKJ6H1SUcafKUU/h+T/ukvkSJSPqJU4+KCEqK+QEqYmo20kFKlC3Bfi0mlDL7t7ZTSvZcEHrR9\n",
       "52Bj+qDVWOfXSUkgo23fLKmU39YpXr6/729z0gWlCK0kwzXfbTUvwJc9j1vRocFHSLHjT9OT4Voo\n",
       "uqXG8xvgoOz+OBE403bZzN8zSROhXUllOH5Bwe8iR6B8IUemNFPmuziJpjuNpkX8btLMuwzHAfdk\n",
       "o7sUBSPymviAUtmLaVQw1s0L2NOFYrdA5XWF3nSkwSdFx6zuptjkPBO6imSAB6TJPwnJ0K0E/Cpf\n",
       "bcv6J1tZTGro8y1gK9Ii53cknVs2VMv2byRdRfVY526SG+BSpfIQLVfeq4JbS4ZbNM+Mu3o/L6tD\n",
       "82ulBKhS2C5dc6aJls7vXnpsJGkBkpvoL5L+abtwciA9rot9bJ8lqfBY21/Ij1VqETVYgeQmPIMU\n",
       "BQYVDaXtYySdR1pnerDCgv6T+bijgOWpVmusjgXsttGpBv8dpBDIZl6neNGxZv9kN+XDopppZTGp\n",
       "wVakH/hb2UV0c1mdNH1VwyqxzpuTXFOXkRaFthjw3W1CvZLhJJVJhtuPHkPQ/Hzfvt/erw5fI4W3\n",
       "voP0o36JAcL2+pGxNKkw1tykKKwHbF9ccHir53dvRpPWA2ahfHmG0cBPgOslrU3JwAgASR8lLb5/\n",
       "gFT3aQfbdxQZa/ujkpYhXbC+R7r4nGa7sEtH0o9sH9RrotetFI5deILX2y2panWFKi9g99K/mVoW\n",
       "bKFzDf5xpHoSNwEvkG5516Cgf7HJPzkvsD49P+wFSCvpZai8mNRLp7fy45uSqoRYNWYfXaRZUdnZ\n",
       "xxukBaXNSHkE8wCFyxvXSOVkONsnN54rFdialtdQUoddSBe9fUhujDJVPxv8muRyOI7kbruQtFhX\n",
       "hJbO72YkXU36Hk4A1qng0plAKtN8AqkEyLZldSDpvaNTsbBlSYv5ZQq43UMy9khaEzhM0vttr1JQ\n",
       "xIX58RJaWI9QPXWFWlnA7i88tKi7dFA60uDbPl7ShSRXzFykRJ8DG7HwJbiA5Lf+KGlG5YHf3icn\n",
       "kCIpupXKBFdxhdyUbzVvAFanZA0aqGX2cSIpzGw8KYLgRMpnuNZBK8lwQOu16En12h+TNJfta3IE\n",
       "VWmckrWw/ahKFPuq8fwG2C0bzKo8RLpLWZk0qXg/KZa8DF227wKw/Q9VyFVRKiewKenOcw5KuE4b\n",
       "xyYlNzbWI/Yhhc6Wiaprua5QK+7Cponq2/o9UH6i2icdafCVarbsRTLSv7D9TN6/n+0DSojqsv01\n",
       "SSeSwizLLohBqreyGXC57bslXUP5Bb6DSIZ+CeAkl6xhA7XMPua1faKkrW1fn91UZXX4YbP7RdKP\n",
       "be9Nnp0VpJVkuAaNWvRVXSDPS9oEmJrdO6VKCWSezWPnUIqjf77owBrPb0hrGT+n5y52nt5hfYNw\n",
       "HjAf02fJXl9ShylKvRGuJ00i3ig6UKkK5Bak8/k84OuevopoGSqvR8C09aV5gQ8BD1cJqWzFXSip\n",
       "caGaR9IX8u4uqlXc7JOONPikxcXzSf7FGyRt6JT0Mx4o84N4U9I7gTlJJ8P8FXR5gFRGYJzt0gu2\n",
       "mYudinsVveXvi1ZnH91K9egboXiFo3SUMmN3JK0dNErHjiL5e/d2ifr27kmGu4Pk965SAbCVWvSQ\n",
       "zoOFSK663ajWWGIHUi7CJFI3tDIdzOo6vyG5w75KqrR5LeUnAu9xifr5/bA9KQntx8D9lCt1cRbp\n",
       "N3YXyTAuo55KlWUDLFpaj8jBDAeTDOwykvZ3+Q5Tld2Fbr3fw6B0qsGfNcfGIulOUjz8+ApyfksK\n",
       "v/szaQZT2pVCukJvBJyjVKirShr6s5J2o6fWR+nEqxpinXcjtV77COlE/EaJsaeTIkj2If0gGk1Y\n",
       "Soe55lv3ufLYeSRt4/KVAFupRQ/ps29P8v3+mdTJrBCSPmD7v6QkneaY7XEUXxOp6/yGlMV9s6Sv\n",
       "2z5JKWS3DJb0PttFS3X0xadsN7JdG1FpRf3n6+TH5nWYquGMra5H7Aks79Tr4V3ANaSkvjLU4S48\n",
       "RtJWJPvcKCT34wpy3kanGvxZJH3U9t22/5rD7/5EmqkXxvYfGs8l/d4VS9Danizpi6QTqehCUjPP\n",
       "khZymhdzShn8vMD3XtKMcl7SHUsj/nvJAiIeBL5h+06lypeF/b623yBlC+9MivSZNf9pEcrf/tdR\n",
       "CbCVWvTYvh/4bo64+g0pdvt6YF/bg2Xc7pkjpk5n+lwAKO7qq+X8zjTqyLxDqbbPB0qOX5108Xya\n",
       "notn0Rj6LUl129eRtA7JOI0izdRLBVg0ySzdT7ZJ1kRS5jFAle5uUxphwk5JVFUKyr1Qg7uw99pj\n",
       "2aTAfulUg/8t4NeSNrf9pO1zcjjjr8oIyV/4zuRoDqU4/CLGsZkJMC3KZltJpV0QTolXi5Oy7+6m\n",
       "eOGzZiaS/Jt3KxUOO8DlKuqdQXIp3Zn1OIUULlqGOvy9dVQCbKnph1LBsm1JiXCnke5+ZiGV0R3M\n",
       "//0vkvthCukCUXZGDTWd35lvkDK4DyFlUZdKNrLdStp+c/vNYynZfrMf1qVkCZUaeTivh9xAipqq\n",
       "8jl2JK0B7E1yu1ZxF9ax9tgnHWnwnVLFx0v6Ljle3fbpA8Sp9sdupEYChRfU+mBuSd9j+hDAPwzw\n",
       "/mlI+pTtK1Wx8FkvFnNOtnIq6VvWV/s+2yfl8T9Tqp5Zljr8vXVUAqxciz7zZVIM/XVOZSIAkLR/\n",
       "wbEiuaVOJ4WXlqLG8xtgmaaLzhfyuVYYtZBP4Nx+k1Rn6T2kO78uOtSuFGACaYL4KdJaRBV3zCiS\n",
       "y3FxUshxlXXDOtYe+1Wuk9lQqaY0MK2+TRnuAv5n+/nGVkGHk0mlhM9p2orSyBPfgtT67Hmndm1V\n",
       "3ELPSDpU0uckHU75WiNTlVfDJC1Gtf+9Jb2vwrhmxtOzUGeqhcq+0/ZVJPfDvbw9iWlAbH/Z9rXN\n",
       "xj7vP7/A8NdsT3bK4ixcLbQfWj2/IWVuHyJpPkl/ImWIlqGRTzCJ9H8pu2jcCJO9lfTbOJtyv5GG\n",
       "jO/mp1VyIurkDlJ5hPvoqcJZhj+TWo+ukrcy4cINeq89luqDPRCdfiUeBzwm6WF6/NVlZphXA/+W\n",
       "1Lg167a9zkAD+qCV0saNmWsdTZ4PJ508G5BOxKJVPxvsQVp4fg9pkXLnCjpU9vc2KBky2B+tNv1o\n",
       "heZw1lYnTK2e35BcIKeQjMIetktVMIXq+QRNtBomC+ni9wuXK7VRNy3XzSJN6rZrRYlea4/nkgIm\n",
       "aqHTDf5GtFZ86GukZsIvtCCjldLGjU48dTR5/iWwhe2HJP2MdOdROHHKqd9q7wzAUrTo7wVA0oNM\n",
       "f95NJs1i9nLBdHxaq0XfKktJOpNk+JdscsNUCSNs9fyG5LNfjLQmsbek512wNWDmmar5BE20GiYL\n",
       "9Vz8WqXlulnAFfn7nBY7b7vsOtc0nCqr1tZ4vNMNfkuLcyRDcnvFW+UGlUsbOzf5dk/hs6VJrowq\n",
       "ESqTneuL2P63pFKzqfxDauYF26UuAK34e5u4mnTLfCPplndHejqCrVZQRiu16FvlS/SkvjfX86/y\n",
       "o2z1/Ib0G17DKWv5ClLv5TIG/x5SIbtGPkGVirKthslCPRe/VqmjbtYapLWMtZr2VTb4ddPpBr/V\n",
       "xbnZSDVwKnfz6X17ptR4uxSS/g1savv3+fXV9MQfF+U/OXzvFlJoZNlIn4/kxy6Sn/eLJcdDa/Vj\n",
       "Gsg9jVeulbRvXtguUwCtci36VukdRtgirZ7fAC+5p07Tc/kOalDUlExHz2x0dSoUT6PFMNlMHRe/\n",
       "VrmAVMn0H0p1s6q4l+a0/akqBx9g0X6mL57WoJVG0ZAy/1o6ESUdRHINzUoq43o75RddXwWOUqrq\n",
       "dzXV6ltPyHp8mhRBUDb8rtnPfZNST9fS1ODvnZxvef9KKrD1uqSPU+5crFyLvsOofH5r+uznDfPu\n",
       "RvZzkeiS2pLpSIvXX2T6IoVl14jquPi1yn9IayJjSL/ZKp6Be7Nr7A7Kt3vs3YWswcxdPK2JVhfn\n",
       "/kO6VWwOqSxbhGhjUjLLEXmrEqo1idSM5YJ8m1j6RLL9Gqk5RSUkNWfqLVBFB1qoH9PEViQj8znS\n",
       "LG5r0qJf4WYXbq0WfSfRyvndksFuJNNRrgxCf5xJKhWxOikgoEpj+VYnd3VwOKlMReO8rjJZXBb4\n",
       "WK99hRLyar577JNON/iNxblxVFuc+xMpWaiVW//Hnao7zpUXTCsZG9vPKtWhOY/Bk3vaQaOsA8A/\n",
       "KNcDtsEOpISSp0klmsvUj0lK2E/nRefRJCO1eNnkpZrWEjqByud3zdnPrfKy7R9LWtz2BKUWhWUZ\n",
       "zsirBve2anRdQ7vHdtKRBl/SaNtvksq1btP0p7JX3P/Y3r9Fdf6Xb59fzm6Q+SrI2BvAqUbHxlTL\n",
       "vmuVc0guocVJC3VVIirmA+62/f18xzAXJWvq5+zBVUhJJe8k3b5/tqQedawlDBs1nt9QT/Zzq0xV\n",
       "6ro1p6Q5qFZOYDgjrxr8Kfvu78+vu22XarMoaVuSF2CaV8F2bT74VulIg0+qJrglqZxA7x/BIiXk\n",
       "XJSN9D/JBZlcvlDXXqQGFecC21GiHIGaulRJWr/pT8MRjXAmKXzuClI0zIlMb2yKcCo9VTovI/lZ\n",
       "P1lSxsdI0UrHkNwRVcoJ1LGWMJzUdX5DPdnPlVEqhncAKZP8dFIt/dLhjLb/m3+ri5Nm2lVLJLfC\n",
       "bqRqm40w7iq/0++R3Mi1JUvVSUcafNtb5seFWxS1Belq/ZHB3jgAFzqVNobyHYnuy4/bkGbV15OS\n",
       "p8rW86mD+Wxvkp//UdKNFWR0OxcXc6qpXyXx6BnbUyXNaXuSUgXSstSxljBs1Hh+Qz3VLiuhVL/9\n",
       "26S1g11tX05yo1aRdSBpwfRWYDdJf8hZ6UPJ47ZLZwn34l8u0Z5xqOlIg6/UZATevmJdNlP2Ddut\n",
       "3ho2ShtPpCcipGgc/h8AJH3V9j559xWSrhxgWLt4UNIytu+RtDDVcgFekPRVUk/elUilo8tyu6Tv\n",
       "AI9KOptqFSJbqUU/7NR4fkMN2c8t0LuuUJV1oQafBVa0PUXSLKTw46E2+K8rdZL7Bz3f5Q9Kynit\n",
       "BhltoyMNPj0x4oeTqjzeQPL7lm28/X+S9iaFSEGFOvTUUNoYeLekD2c3xFJUM3KtItLM/inSIuFb\n",
       "ku4hfSdFF5G3JcUpb0K6cyrl38xsADxM8r3fQJrRFUL11KLvBOo6v2vJfm6B15wK3z2tVO2zFR4n\n",
       "LTy/SgrtfKZV5SrQqITbisv10hbHt5WONPi5MBWSFrL9l7z7WhWrZtjMGJJPsLk9YNnGI3WUNt4d\n",
       "ODcvbD1K+UqZLVOHnze7YA6lZ0Fq9goylpf0EVK46+dIC5ebDDxqGnXUoh92ajy/hztiqc66QnMA\n",
       "9+VF04+ROrRdRJqQbNyi7ELYPrkGMWeQoqYaUWgdlR/SkQa/iSk5QuZvpFvXUpEl2VjPQvriV6XE\n",
       "bLKBWihtrNR05UtOTS5Ot3143l+lL25LSPocqf1a1d6ndTQPR9KyJF9tw3Vx/wBv700dteg7iZbO\n",
       "78xwRizVWVeor+5UVTtfDSd9FWArU+qirXS6wf8yKZLjS6RIm63LDJb0K5JBWQhYjjSbLNv2bAtS\n",
       "kbIrbR8h6faCx/4504dwfoZ0Cz9ctNr7FOqping9KZJjH+BS9ypRPAgt16LvMFo6vxsMY8RSnXWF\n",
       "tuv1utv2gRX1Gk7qKMDWNjrS4Df5at8NHNX0p7K+2hVt7ybpWqeO9FXKjFYtbXw0cHyF47WLVnuf\n",
       "Qj1VEeclzWbXJ7loJtku6ruu02c8bNR4fsMwRizVnBn6JOlCMYpU66nTe3X0Rx0F2NpGRxp8Uu32\n",
       "PUmx2o3ZQuP2rkwUwyhJK5Bal81KiqcvS9XSxj+ls25HW+19CvVURRwLvI901zUnyZ1RlDp9xsPJ\n",
       "nqRzvFE7pZmyrr6Ws587AdvT1YvJkS4zInUUYGsbnWrw18sRJLOQFl6fptrs51RSM+MJpDo0xw78\n",
       "9rfjVNr4SlKykJ3bDBYYt6mkp/rxcQ5HHH5LvU8zpaNI+qARq32w7fsGe3Mv6vQZDxu298iP42sQ\n",
       "13L2cyeQAyMaLEg1l2MnUEcBtrbRkQbf9tIAkk4CDrNt5cbdJUU1qinuCSxDih8vRT4RGxmA90j6\n",
       "dr4dL0J/Ps7aqt+VYDZSVuZVkiaS4pwLIWkn28eT/P/NdJPi4Qtj++Nl3t+LOn3Gw0aezEDPhGYS\n",
       "eUJju2yFyDqynzuB40j/x3lIv9tvD/z2jqWOAmxtoyMNfhMfsm2Y1rh74ZLj9wSWyzVs3gVcQ4q0\n",
       "KcOppNnwTaRIn5Mp+IMaiup3JWjFMDQ6d32DZOBfYxhmLh32fVbG9jJQy4QG6sl+HjYkLU/KqViJ\n",
       "VJLgGNI60Yy6RtNyAbZ20ukG/2mlevS3k+q/lG2IMMW5R6btl1St5OorTXHNl0jas4KMTqCyYXDu\n",
       "3EW6QEwgLbpewPTJT0F5Wp3QQD3Zz8PJ4cC2tidLOpiUmPcgyfV34bBqVo2WC7C1k043+F8huRE2\n",
       "JIWt/ajk+IdzeOQNpNZj/xrk/X3xkKRdgL+QGjK8nGcluHgP1k6gZcNg+3ZSaYS5STOxB+kpyxuU\n",
       "p9UJDdST/TycjLJ9l6T3AbPb/juASrbw7CDqKMDWNjra4Nt+ldbqaUwglV39FOnHUKV5yaykei0N\n",
       "3/Oz9JQ3ntCCbkNNy4ZB0ppZzkqk6qHfqVPBEciXSWWAq05oasl+HmbezI/rA1dCKh/N8JQfqYM6\n",
       "CrC1jY42+K2Sa44f2aKMt2XrOjWfmKHIhuEn9KR8f5jynYl2I+UW7NRi8lWQ+JntaVnbkk6lZMnq\n",
       "OrKfh5mrJN1EisrZWNKipNyE3w+vWpWpowBb25ipDX4d1JStO+yohsYjtr/QBtVGHLms8D7APJIa\n",
       "375cBg4AAAfPSURBVGkXPc3Ey1BH9vOwYfswSRcCL+RM4Q8Bx9m+YLh1q0gdBdjaRhj8wakjW7cT\n",
       "qKXxSNA6to8EjpS0j+1DWhRXR/bzsGL7n03P/0W1tbaOoKYCbG0jDP7g1JGt2wnU0XgkqJcjlfr7\n",
       "LkXqOXyQ7bJJU3VkPwcjhDD4g3MqqS7OBNLqe9kWiZ3C3yV9F3ishcYjQb2cCFxHqqa4FinHo2wp\n",
       "4Dqyn4MRQhj8fmgqbfxbSbPnMgC759LGLS0EDwe2987JZ68BnwZuG2aVApjXdqNt5p2SNis6sM7s\n",
       "52DkMENl5Q0xvUsbz9BI+hipvMTHSYW7lhlejQJgttwUh+xiK/N7bM5+/h8pJ+IBkmsoCPokDP7I\n",
       "4RhSaecfkhZt9xtedQJS3P1NubbOTZSIw++V/bwkKWR2EVL5kCDokzD4I4fXSWF/o3OJhbeGWZ8g\n",
       "uVS7SL/DKfQkIRXG9u22dwHGAx8hzfSDoE/Ch98//ZXiHY7SxnXQTVpwvlTSl6hgXILa2R9Y2fZT\n",
       "ubTAeaRcicJE9nNQhjD4/dNJpY3rYHNSc+XLSLPBiO4Yfl62/RTQaE9YJZY+sp+DwoTB74dOLnFa\n",
       "kVlJxbkWJ/VOfY4ZsFHGzICkRpnqKZJOJ3VUW4UK3ZEi+zkoQxj8kcOZpIXaXYE/kDqAlW2nF9TD\n",
       "M6S7xzPoad15PR2ajh/MPITBHzlMJZWJ3sf2WZJ2HG6FRiqdnn4fzLxElM7IYTQpU/h6SWuTWusF\n",
       "QTCCCIM/cphAKkr1E1JS2QxX8TMIgtYIgz9yWAC4j9S160ng/cOrThAEQ0348EcOX6cnzHQp4BHS\n",
       "QmEQBCOEru7uCAwYaUgaA5xr+3PDrUsQBENHuHRGJqOBRYdbiSAIhpZw6YwQJD1BT5z3aOCXw6hO\n",
       "EATDQLh0RhCS5rD9iqQFbT823PoEQTC0hEtnhCBpf1JZZIBfSPr+MKoTBMEwEAZ/5LCx7R8A2N6c\n",
       "8q30giCYwQmDP3KYkpuwN6J0uoZZnyAIhphYtB05HAPcI+leYAlSxm0QBCOIMPgjh4eB1UnhmP+y\n",
       "PWmY9QmCYIgJgz9yOMD2GsBTw61IEATDQxj8kUO3pD8CJpVK7m4s4gZBMDIIgz9yOJFosBEEI5ow\n",
       "+COHM0g9bUeTInQWHF51giAYasLgjxwuIP2/308Kx72D1PYwCIIRQsThjxzG2d4AuAX4ODD7MOsT\n",
       "BMEQEwZ/5PCKpC5gTtuvAuOGW6EgCIaWMPgjh/OBHwH/kHQLMHmY9QmCYIgJH/5MjqST6Ol0NYoU\n",
       "kvkY8OZw6hUEwdATBn/mZwWSv/4M4K/DrEsQBMNI1MMfAUhaBvgKKSzzBuA02w8Nr1ZBEAw1YfBH\n",
       "GJLWBL4FvN/2KsOtTxAEQ0e4dEYIkuYCNgW2AOYATh9ejYIgGGpihj+TI2lzkpH/IHAecJbth4dX\n",
       "qyAIhoMw+DM5kqYCDwB39fpTt+2thkGlIAiGiXDpzPyskx8bV/auXq+DIBghxAw/CIJghBCZtkEQ\n",
       "BCOEMPhBEAQjhDD4QRAEI4RYtA1mSCQdCawGjAEWA/6Z//RL26dUlDknqTOYSIvbh9g+J//t28CO\n",
       "pEnS921f0GvswsA1thfptX+q7ZhYBR1BGPxghsT2rgCSFgKutb1cDWK/Dzxi+0uS5iNVFr0aWBj4\n",
       "MvAxYCxws6RrbT9XwzGDYMgIgx/M6HQ1v5C0OHAcMDfwCvAt27dLOplUEno5YC7gINu9s42vJTV5\n",
       "x/YkSc8CCwAbAufZngxMknQt8FngtKJKSvoocCzpN/c6MMH2Q5I2AA4gtZ58GNjJ9rOSHiE1q1kW\n",
       "WBc4BnhPFneA7YuKHjsIGsStZjCzcTrJrfMxYA/gD5LG5L8tCKxMyk04XNJ7mgfavtL2f2FahvIY\n",
       "4D6S0X+i6a2Pk1pFlmEP4Oe2VwR+A6yc7yJ+DKxne3ngz8BP8vu7gUttL5H1fdj2x0lF8NYoeewg\n",
       "AMLgBzMR2Qf/Idt/BLB9K/AsySffDRxve6rtR4GbgNX7kfNF4BfAZran0OsuIjN1kNfkDmONRJeL\n",
       "gSMl/Y50p3EW6eLzQeBaSXcCu5DWIxrcmh9vAj4v6YKs80H9fglBMABh8IOZiVG83Th30eO6nNLr\n",
       "vW9rAiPpm8DPgHVt35N3Pwq8t+ltC+Z9zTxH8u83M3/ej+3zgOWB24DdSS6aUcCNtpfLaxArAV9q\n",
       "Gv9aHvsQsASpp8EaWUYQlCYMfjDTYPv/27tDlgiCMIzjfzCoYLaa5PkGotj8BHom4ZKCYDWfp9f8\n",
       "BooYD4XDKFwQk0nOomh4EZNBrBoVNMyIy2K5dOA8vzi7Oztl351532X2DXiStAIgaZ6U974nBf61\n",
       "3D5Dml1fVa+XtEwKxosR8VA51AdWJU3mNMwScFm79zvwKKlRad4ELnLfJ8BcRBwBbVIt4RpYkDSb\n",
       "z2/xm9KpjmuLlLc/I60CpvPup2ZDcdHW/oPq/iBN4FBSh1QcbUTEh6QvYErSDTBOKo7Wv7LZAyaA\n",
       "c0k/bRsRMZDUBQakZ6YVES9/jKMJHEhqk/L/t6QADbAPHEvaAT6B7Yh4lbQO9CSNAc+5j7oucCrp\n",
       "jrQq2c0vN7OheC8dK0L+t28/InqjHovZqDilY2ZWCM/wzcwK4Rm+mVkhHPDNzArhgG9mVggHfDOz\n",
       "Qjjgm5kVwgHfzKwQ38cytZXpDklRAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18a04c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "n_entries = db.paris.find().count()\n",
    "\n",
    "pipeline = [\n",
    "    {'$group': {'_id' : '$created.user',\n",
    "                 'count' : {'$sum' : 1}}},\n",
    "    {'$sort': {'count':-1}},\n",
    "    {'$limit':20}\n",
    "    ]\n",
    "\n",
    "top_20_users = [(doc['_id'], 100 * doc['count']/1.0/n_entries) for doc in db.paris.aggregate(pipeline)]\n",
    "\n",
    "values = [user[1] for user in top_20_users]\n",
    "xlabels = [user[0] for user in top_20_users]\n",
    "\n",
    "N = len(values)\n",
    "ind = np.arange(N)    \n",
    "legend = 'Ratio of entries contribution for the top 20 users' \n",
    "width = 0.4       \n",
    "\n",
    "plt.bar(ind, values, width, label=legend)\n",
    "plt.legend()\n",
    "\n",
    "# code to rotate x labels\n",
    "# source: http://stackoverflow.com/questions/10998621/rotate-axis-text-in-python-matplotlib\n",
    "x = range(len(xlabels))\n",
    "plt.xticks(x,  xlabels)\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=90)\n",
    "\n",
    "plt.ylabel('Entries contribution [% of overall entries]')\n",
    "plt.xlabel('Top 20 Users')\n",
    "plt.xticks(ind + width/2., xlabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Looking at the zipcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at some zipcodes implemented in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75004\n",
      "77410\n",
      "77410\n",
      "91170\n",
      "77400\n",
      "92230\n",
      "78630\n",
      "91160\n",
      "95290\n",
      "77000\n",
      "94800\n",
      "93200\n",
      "91180\n",
      "95450\n",
      "91300\n",
      "78150\n",
      "78350\n",
      "77500\n",
      "78000\n",
      "78310\n",
      "77184\n",
      "78390\n",
      "77230\n",
      "91630\n",
      "95000\n",
      "93150\n",
      "95480\n",
      "93250\n",
      "78340\n",
      "94500\n",
      "91250\n",
      "91460\n",
      "77500\n",
      "78140\n",
      "92210\n",
      "95370\n",
      "77100\n",
      "95310\n",
      "75020\n",
      "91160\n",
      "91400\n",
      "95610\n",
      "94200\n",
      "77600\n",
      "93800\n",
      "77165\n",
      "95330\n",
      "95540\n",
      "94190\n",
      "95350\n",
      "91940\n",
      "78140\n",
      "78960\n",
      "95520\n",
      "77290\n",
      "78190\n",
      "78630\n",
      "78410\n",
      "91230\n",
      "95470\n",
      "95140\n",
      "78150\n",
      "77700\n",
      "95520\n",
      "78690\n",
      "92140\n",
      "77340\n",
      "95150\n",
      "77170\n",
      "94120\n",
      "78920\n",
      "91480\n",
      "75015\n",
      "93600\n",
      "77160\n",
      "77410\n",
      "93190\n",
      "91300\n",
      "95570\n",
      "95500\n",
      "94220\n",
      "93420\n",
      "75019\n",
      "78140\n",
      "95480\n",
      "93120\n",
      "92120\n",
      "92160\n",
      "78630\n",
      "95480\n",
      "77090\n",
      "94310\n",
      "93190\n",
      "78310\n",
      "93420\n",
      "75019\n",
      "95650\n",
      "93120\n",
      "78190\n",
      "95470\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    {'$match' : {'address.postcode' : {'$exists':1}}},\n",
    "    {'$project' : {'street' : '$address.postcode'}},\n",
    "    {'$limit':100}\n",
    "    ]\n",
    "\n",
    "for doc in db.paris.aggregate(pipeline):\n",
    "    print doc['street']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data validity seems to be very good. All of these zipcode are ether from Paris, or from nearby where it is connected to a metro line. \n",
    "\n",
    "Uniformity is also very good, as all the entries are consistent with a standard schema.\n",
    "\n",
    "But is this information frequent in the database ? I mean, could it be used to split our data analysis per neighborhood ('arrondissement' in French) for instance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 18588534\n",
      "Number of nodes with postal code: 31946 (0.2% of node population)\n",
      "Number of amenities with postal code: 6938 (7.5% of amenity population)\n"
     ]
    }
   ],
   "source": [
    "n_nodes = db.paris.find({\"type\":\"node\"}).count()\n",
    "print 'Number of nodes: {}'.format(n_nodes)\n",
    "n_nodes_postcode = db.paris.find({'address.postcode': {'$exists':1}, 'type':'node'}).count()\n",
    "print 'Number of nodes with postal code: {0} ({1:0.1f}% of node population)'.format(n_nodes_postcode, 100.0 * n_nodes_postcode /n_nodes)\n",
    "n_amenities = db.paris.find({'amenity': {'$exists':1}}).count()\n",
    "n_amenities_postcode = db.paris.find({'address.postcode': {'$exists':1}, \n",
    "                                            'amenity': {'$exists':1}}).count()\n",
    "print 'Number of amenities with postal code: {0} ({1:0.1f}% of amenity population)'.format(n_amenities_postcode,\n",
    "                                                                                        100.0 * n_amenities_postcode /n_amenities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only a small part of amenities have been detailed with a relevant postcode. We can see that there is a completeness issue with our data.\n",
    "\n",
    "In fact, most of the postcode information (as well as lots of other entries) is transfered through the 'relation' object. It limits the redundancy in the data, but make it more difficult to get all the relevant info from one node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{_id: ObjectId('5724dc792c8cbf1d8cd899c9'),\n",
      " address: {postcode: 75016;75116},\n",
      " created: {changeset: 36281583,\n",
      "           timestamp: 2015-12-31T12:30:56Z,\n",
      "           uid: 90780,\n",
      "           user: Verdy_p,\n",
      "           version: 44},\n",
      " id: 9517,\n",
      " landuse: residential,\n",
      " members: [{ref: 517969463, type: node},\n",
      "           {ref: 184994832, type: way},\n",
      "           {ref: 164247236, type: way},\n",
      "           {ref: 31564797, type: way},\n",
      "           {ref: 30677982, type: way},\n",
      "           {ref: 164248374, type: way},\n",
      "           {ref: 30677984, type: way},\n",
      "           {ref: 30660063, type: way},\n",
      "           {ref: 165166079, type: way},\n",
      "           {ref: 165166078, type: way},\n",
      "           {ref: 307467058, type: way},\n",
      "           {ref: 30660060, type: way},\n",
      "           {ref: 22966698, type: way},\n",
      "           {ref: 164338492, type: way},\n",
      "           {ref: 164286226, type: way},\n",
      "           {ref: 23636206, type: way},\n",
      "           {ref: 164245443, type: way},\n",
      "           {ref: 23636204, type: way},\n",
      "           {ref: 164286227, type: way},\n",
      "           {ref: 32809940, type: way}],\n",
      " name: Paris 16e Arrondissement,\n",
      " type: relation}\n"
     ]
    }
   ],
   "source": [
    "MyPrettyPrinter().pprint(db.paris.find_one({'type':'relation', 'address.postcode': {'$exists':1}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If te goal is to split our analysis by specific region in the map (like postcode), a preprocess should be done before importing the data in MongoDB in order to associate each element with the relevant postcode. But this would make the database heavier, creating a lot of redundancy in the data structure.\n",
    "\n",
    "Another solution could be using geographical data (lat + lon) to locate the element and determine which postcode it can be associated with. But this would imply knowing the geographical perimeter of each postal code, which is not possible without using an external API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Is there any changes to be done with the 'street' entries ?\n",
    "\n",
    "Let's look at some examples of street names in order to identify potential quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quai Marcel Dassault\n",
      "Boulevard Henri Barbusse\n",
      "Avenue de l'Ocanie\n",
      "Rue Sainte-Opportune\n",
      "Rue Pierre Brossolette\n",
      "Rue Ledru-Rollin\n",
      "Avenue Franklin Roosevelt\n",
      "route de Romainville\n",
      "Rue du Disque\n",
      "Avenue Gabriel Pri\n",
      "Rue Duhesme\n",
      "Rue Mirabeau\n",
      "Rue de Grenelle\n",
      "Avenue de la Division Leclerc\n",
      "Rue Gabriel Pri\n",
      "Alle Ren Descartes\n",
      "Rue des Plantes\n",
      "Place de l'Htel de Ville\n",
      "avenue Joliot Curie\n",
      "Quai Branly\n",
      "Quai Branly\n",
      "Quai Branly\n",
      "Quai Branly\n",
      "Rue de la Rpublique\n",
      "Rue Yves le Coz\n",
      "Rue de Paris\n",
      "Rue de la Paroisse\n",
      "Rue de la Paroisse\n",
      "Rue Corneille\n",
      "Rue Jean Mermoz\n",
      "Boulevard de Bonne Nouvelle\n",
      "quai de Gesvres\n",
      "Boulevard Kellermann\n",
      "Grande Rue\n",
      "Rue du Bas Igny\n",
      "Avenue mile Cossonneau\n",
      "Rue Pablo Neruda\n",
      "Avenue Pablo Picasso\n",
      "Boulevard Saint-Germain\n",
      "Rue Maurice Utrillo\n",
      "Rue de la Ppinire\n",
      "Quai Branly\n",
      "Rue Velpeau\n",
      "Quai Saint-Bernard\n",
      "Rue Saint-Honor\n",
      "Rue de Montpensier\n",
      "Rue des Lavandires Sainte-Opportune\n",
      "Rue Saint-Honor\n",
      "Rue du Parc Royal\n",
      "Boulevard Saint-Germain\n",
      "Rue de la Station\n",
      "Rue Traversire\n",
      "Avenue du Gnral Leclerc\n",
      "Impasse Robiquet\n",
      "Rue de Rennes\n",
      "Rue Lon Jouhaux\n",
      "Avenue Daniel Perdrige\n",
      "Rue Daunou\n",
      "Rue Daubenton\n",
      "Rue de la Bcherie\n",
      "Rue de Lanneau\n",
      "Rue Lacpde\n",
      "Rue de la Harpe\n",
      "Rue du Colise\n",
      "Boulevard des Capucines\n",
      "Rue du Cardinal Lemoine\n",
      "Rue de Bercy\n",
      "Boulevard des Italiens\n",
      "Rue du Faubourg Montmartre\n",
      "Boulevard Montmartre\n",
      "Rue Rodier\n",
      "Rue de Lancry\n",
      "Place de la Mairie\n",
      "Rue Oberkampf\n",
      "Rue Jacquard\n",
      "place de la Bastille\n",
      "Rue de la Roquette\n",
      "Rue de Charonne\n",
      "Boulevard Voltaire\n",
      "Rue Oberkampf\n",
      "Rue de Nemours\n",
      "Avenue d'Ivry\n",
      "Rue Daguerre\n",
      "Rue de Gergovie\n",
      "Rue de la Convention\n",
      "Chausse de la Muette\n",
      "Avenue Klber\n",
      "Boulevard Gouvion-Saint-Cyr\n",
      "Rue la Vieuville\n",
      "Avenue Corentin Cariou\n",
      "Boulevard Rouget de Lisle\n",
      "Rue Mabillon\n",
      "Rue Pierre Leroux\n",
      "Rue du Gnral Leclerc\n",
      "Boulevard de l'Hpital\n",
      "Place du Gnral de Gaulle\n",
      "Rue de Longjumeau\n",
      "Boulevard Kellermann\n",
      "Rue Crozatier\n",
      "Rue Winston Churchill\n"
     ]
    }
   ],
   "source": [
    "### Looking at the 'street' field\n",
    "pipeline = [\n",
    "    {'$match' : {'address.street' : {'$exists':1}}},\n",
    "    {'$project' : {'street' : '$address.street'}},\n",
    "    {'$limit':100}\n",
    "    ]\n",
    "\n",
    "for doc in db.paris.aggregate(pipeline):\n",
    "    print doc['street']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am a bit astonished by the quality of the street name. I redid the test with 1000 more names, but I could not spot any uniformity issue, and all the names seemed to be legit, which let me believe that there is no validity issue. \n",
    "\n",
    "I wonder if some process in the OSM database has already been done to correct automatically street entries from human in order to increase data quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
